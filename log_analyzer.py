#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨èƒ½ Nginx æ—¥å¿—åˆ†æå™¨ï¼ˆv8 - æ”¯æŒå¤šæ–‡ä»¶ + æ—¶é—´çª—å£ + æ€§èƒ½ä¼˜åŒ– + åŠŸèƒ½å¢å¼ºï¼‰
ä½œè€…ï¼šXgrug
"""

import re
import gzip
from collections import defaultdict, Counter
from datetime import datetime, timedelta
from functools import lru_cache
import argparse
import os
import json
import csv
import sys

# æ—¥å¿—æ­£åˆ™ï¼ˆå…¼å®¹ combined æ ¼å¼ï¼‰
LOG_PATTERN = re.compile(
    r'(?P<ip>\S+) \S+ \S+ \[(?P<time>[^\]]+)\] '
    r'"(?P<method>\S+) (?P<path>\S+) \S+" '
    r'(?P<status>\d+) (?P<size>\S+) '
    r'"(?P<referer>[^"]*)" "(?P<ua>[^"]*)"'
)

TIME_FORMAT = "%d/%b/%Y:%H:%M:%S %z"

DEFAULT_SENSITIVE_PATHS = {
    '/login', '/register', '/admin', '/export', '/backup',
    '/wx/login', '/api/wx/login-check', '/user/reset', '/oauth',
    '/api/admin', '/manage', '/console', '/debug', '/test'
}


class LogAnalyzer:
    """Nginxæ—¥å¿—åˆ†æå™¨ä¸»ç±»"""

    def __init__(self, args):
        self.args = args
        self.time_start, self.time_end = get_time_window(args)
        self.ip_details = defaultdict(lambda: {
            'paths': Counter(),
            'uas': Counter(),
            'statuses': Counter(),
            'total': 0
        })
        self.total_lines = 0
        self.filtered_lines = 0
        self.output_format = getattr(args, 'output_format', 'text')

    def anonymize_ip(self, ip):
        """åŒ¿ååŒ–IPåœ°å€ï¼ˆéšè—æœ€åä¸€æ®µï¼‰"""
        if self.args.anonymize_ip:
            parts = ip.split('.')
            if len(parts) == 4:
                return '.'.join(parts[:-1] + ['x'])
        return ip

    def load_and_parse_logs(self, logfiles):
        """åŠ è½½å¹¶è§£ææ—¥å¿—æ–‡ä»¶"""
        if self.time_start:
            print(
                f"ğŸ•’ æ—¶é—´çª—å£: {self.time_start.strftime('%Y-%m-%d %H:%M:%S %z')} â†’ {self.time_end.strftime('%Y-%m-%d %H:%M:%S %z')}\n")

        for logfile in logfiles:
            if not os.path.exists(logfile):
                self._print_warning(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ â†’ {logfile}")
                continue
            try:
                with open_log_file(logfile) as f:
                    for line in f:
                        self.total_lines += 1
                        match = LOG_PATTERN.search(line)
                        if not match:
                            continue

                        try:
                            log_time = parse_log_time(match.group('time'))
                        except Exception:
                            continue

                        if self.time_start and (log_time < self.time_start or log_time > self.time_end):
                            continue

                        # è¿‡æ»¤çŠ¶æ€ç 
                        if self.args.filter_status:
                            status_class = classify_status_code_class(match.group('status'))
                            if status_class != self.args.filter_status:
                                continue

                        self.filtered_lines += 1

                        ip = match.group('ip')
                        raw_path = match.group('path')
                        path = raw_path.split('?')[0]  # ç¼“å­˜ç»“æœé¿å…é‡å¤è®¡ç®—
                        status = match.group('status')
                        ua = match.group('ua').strip() or '-'

                        self.ip_details[ip]['paths'][path] += 1
                        self.ip_details[ip]['uas'][ua] += 1
                        self.ip_details[ip]['statuses'][status] += 1
                        self.ip_details[ip]['total'] += 1
            except Exception as e:
                self._print_error(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥ï¼š{logfile} â†’ {e}")
                continue

        if self.time_start:
            print(f"ğŸ“Š å…±è¯»å– {self.total_lines:,} è¡Œï¼Œ{self.filtered_lines:,} è¡Œåœ¨æ—¶é—´çª—å£å†…\n")

    def _print_warning(self, message):
        """æ‰“å°è­¦å‘Šä¿¡æ¯"""
        if self.output_format == 'text':
            print(f"âš ï¸  {message}")

    def _print_error(self, message):
        """æ‰“å°é”™è¯¯ä¿¡æ¯"""
        if self.output_format == 'text':
            print(f"âŒ {message}")

    def analyze(self):
        """æ‰§è¡Œåˆ†æä»»åŠ¡"""
        # åŠ è½½æ—¥å¿—
        self.load_and_parse_logs(self.args.logfiles)

        # æ ¹æ®ä¸åŒæ¨¡å¼æ‰§è¡Œåˆ†æ
        if self.args.group_by == "freq-status":
            self._group_by_freq_status()
            return

        # æ„å»ºå…¨å±€ç»Ÿè®¡
        self._build_global_stats()

        # æ‰§è¡Œç‰¹å®šæŸ¥è¯¢
        if self.args.path:
            self._analyze_path()
            return

        if self.args.ip:
            self._analyze_ip()
            return

        # æ‰§è¡Œå…¨å±€åˆ†æ
        self._global_analysis()

    def _build_global_stats(self):
        """æ„å»ºå…¨å±€ç»Ÿè®¡æ•°æ®"""
        self.path_details = defaultdict(lambda: {
            'ips': Counter(),
            'statuses': Counter(),
            'uas': Counter(),
            'total': 0
        })
        self.ip_counter = Counter()
        self.path_counter = Counter()
        self.status_counter = Counter()
        self.status_class_counter = Counter()

        for ip, detail in self.ip_details.items():
            self.ip_counter[ip] = detail['total']
            for path, cnt in detail['paths'].items():
                self.path_counter[path] += cnt
                self.path_details[path]['ips'][ip] += cnt
                self.path_details[path]['total'] += cnt
            for status, cnt in detail['statuses'].items():
                self.status_counter[status] += cnt
                self.status_class_counter[classify_status_for_display(status)] += cnt
            for ua, cnt in detail['uas'].items():
                for path in detail['paths']:
                    self.path_details[path]['uas'][ua] += cnt

    def _group_by_freq_status(self):
        """æŒ‰é¢‘ç‡å’ŒçŠ¶æ€ç åˆ†ç»„åˆ†æ"""
        groups = {
            'ğŸ”´ é«˜é¢‘ + é«˜é”™è¯¯ç‡': [],
            'ğŸŸ  é«˜é¢‘ + ä½é”™è¯¯ç‡ï¼ˆå¯èƒ½åˆæ³•ï¼‰': [],
            'ğŸŸ¡ ä¸­é¢‘ + æ•æ„Ÿè·¯å¾„é›†ä¸­': [],
            'ğŸ”µ ä¸­é¢‘ + é«˜é”™è¯¯ç‡ï¼ˆéæ•æ„Ÿï¼‰': [],
            'ğŸŸ¢ ä½é¢‘ + å…¨æˆåŠŸ': [],
            'âšª ä½é¢‘ + é«˜é”™è¯¯ç‡': [],
        }

        for ip, detail in self.ip_details.items():
            total = detail['total']
            error_count = sum(
                cnt for status, cnt in detail['statuses'].items()
                if 400 <= int(status) < 600
            )
            error_rate = error_count / total if total > 0 else 0

            sensitive_count = sum(
                cnt for path, cnt in detail['paths'].items()
                if is_sensitive_path(path, self.args.sensitive_paths)
            )
            sensitive_ratio = sensitive_count / total if total > 0 else 0

            if total >= self.args.high_freq:
                if error_rate >= self.args.error_rate:
                    groups['ğŸ”´ é«˜é¢‘ + é«˜é”™è¯¯ç‡'].append((ip, total, error_rate, sensitive_ratio))
                else:
                    groups['ğŸŸ  é«˜é¢‘ + ä½é”™è¯¯ç‡ï¼ˆå¯èƒ½åˆæ³•ï¼‰'].append((ip, total, error_rate, sensitive_ratio))
            elif total >= self.args.mid_freq:
                if sensitive_ratio >= self.args.sensitive_ratio:
                    groups['ğŸŸ¡ ä¸­é¢‘ + æ•æ„Ÿè·¯å¾„é›†ä¸­'].append((ip, total, error_rate, sensitive_ratio))
                elif error_rate >= self.args.error_rate:
                    groups['ğŸ”µ ä¸­é¢‘ + é«˜é”™è¯¯ç‡ï¼ˆéæ•æ„Ÿï¼‰'].append((ip, total, error_rate, sensitive_ratio))
            else:
                if error_rate == 0:
                    groups['ğŸŸ¢ ä½é¢‘ + å…¨æˆåŠŸ'].append((ip, total, error_rate, sensitive_ratio))
                elif error_rate >= self.args.error_rate:
                    groups['âšª ä½é¢‘ + é«˜é”™è¯¯ç‡'].append((ip, total, error_rate, sensitive_ratio))

        if self.output_format == 'json':
            result = {}
            for group_name, ips in groups.items():
                if ips:
                    result[group_name] = []
                    sorted_ips = sorted(ips, key=lambda x: x[1], reverse=True)[:self.args.top]
                    for ip, total, err, sens in sorted_ips:
                        result[group_name].append({
                            'ip': self.anonymize_ip(ip),
                            'requests': total,
                            'error_rate': round(err * 100, 1),
                            'sensitive_ratio': round(sens * 100, 1)
                        })
            print(json.dumps(result, ensure_ascii=False, indent=2))
        elif self.output_format == 'csv':
            writer = csv.writer(sys.stdout)
            writer.writerow(['group', 'ip', 'requests', 'error_rate_%', 'sensitive_ratio_%'])
            for group_name, ips in groups.items():
                if ips:
                    sorted_ips = sorted(ips, key=lambda x: x[1], reverse=True)[:self.args.top]
                    for ip, total, err, sens in sorted_ips:
                        writer.writerow([
                            group_name,
                            self.anonymize_ip(ip),
                            total,
                            round(err * 100, 1),
                            round(sens * 100, 1)
                        ])
        else:  # text format
            print("ğŸ” æŒ‰ [è¯·æ±‚é¢‘ç‡ + çŠ¶æ€ç ç‰¹å¾] åˆ†ç»„çš„ IP åˆ—è¡¨\n")
            any_output = False
            for group_name, ips in groups.items():
                if ips:
                    any_output = True
                    print(f"{group_name}:")
                    sorted_ips = sorted(ips, key=lambda x: x[1], reverse=True)[:self.args.top]
                    for ip, total, err, sens in sorted_ips:
                        print(f"  - {self.anonymize_ip(ip):<15}: {total:>6} æ¬¡, "
                              f"é”™è¯¯ç‡ {err * 100:5.1f}%, "
                              f"æ•æ„Ÿæ¥å£ {sens * 100:5.1f}%")
                    print()
            if not any_output:
                print("âœ… æœªå‘ç°ç¬¦åˆå½“å‰é˜ˆå€¼æ¡ä»¶çš„ IP")

    def _analyze_path(self):
        """åˆ†æç‰¹å®šè·¯å¾„"""
        clean_path = self.args.path.split('?')[0]
        if clean_path not in self.path_details:
            if self.output_format == 'text':
                print(f"âŒ è·¯å¾„ '{self.args.path}' åœ¨æŒ‡å®šæ—¶é—´çª—å£å†…æœªå‡ºç°")
            return

        detail = self.path_details[clean_path]

        if self.output_format == 'json':
            result = {
                'path': clean_path,
                'total_requests': detail['total'],
                'status_distribution': {},
                'top_ips': [],
                'top_user_agents': []
            }

            for status, cnt in detail['statuses'].most_common():
                cls = classify_status_for_display(status).split()[0]
                result['status_distribution'][status] = {
                    'count': cnt,
                    'class': cls
                }

            for ip, cnt in detail['ips'].most_common(10):
                result['top_ips'].append({
                    'ip': self.anonymize_ip(ip),
                    'count': cnt
                })

            for ua, cnt in detail['uas'].most_common(5):
                display_ua = ua[:60] + '...' if len(ua) > 60 else ua
                result['top_user_agents'].append({
                    'user_agent': display_ua,
                    'count': cnt
                })

            print(json.dumps(result, ensure_ascii=False, indent=2))
        elif self.output_format == 'csv':
            writer = csv.writer(sys.stdout)
            writer.writerow(['type', 'value', 'count'])

            # çŠ¶æ€ç åˆ†å¸ƒ
            for status, cnt in detail['statuses'].most_common():
                cls = classify_status_for_display(status).split()[0]
                writer.writerow(['status', f"{status} ({cls})", cnt])

            # Top IPs
            for ip, cnt in detail['ips'].most_common(10):
                writer.writerow(['ip', self.anonymize_ip(ip), cnt])

            # Top User-Agents
            for ua, cnt in detail['uas'].most_common(5):
                display_ua = ua[:60] + '...' if len(ua) > 60 else ua
                writer.writerow(['user_agent', display_ua, cnt])
        else:  # text format
            print(f"ğŸ” è¯¦ç»†åˆ†æè·¯å¾„: {clean_path}")
            print(f"æ€»è®¿é—®æ¬¡æ•°: {detail['total']}")

            print("\nğŸ“Š çŠ¶æ€ç åˆ†å¸ƒ:")
            for status, cnt in detail['statuses'].most_common():
                cls = classify_status_for_display(status).split()[0]
                print(f"  - {status} ({cls}): {cnt} æ¬¡")

            print(f"\nğŸŒ Top {min(10, len(detail['ips']))} è®¿é—® IP:")
            for ip, cnt in detail['ips'].most_common(10):
                print(f"  - {self.anonymize_ip(ip)}: {cnt} æ¬¡")

            print(f"\nğŸ“± Top User-Agent (å‰ 5):")
            for ua, cnt in detail['uas'].most_common(5):
                display_ua = ua[:60] + '...' if len(ua) > 60 else ua
                print(f"  - {display_ua}: {cnt} æ¬¡")

    def _analyze_ip(self):
        """åˆ†æç‰¹å®šIP"""
        if self.args.ip not in self.ip_details:
            if self.output_format == 'text':
                print(f"âŒ IP {self.args.ip} åœ¨æŒ‡å®šæ—¶é—´çª—å£å†…æœªå‡ºç°")
            return

        detail = self.ip_details[self.args.ip]

        if self.output_format == 'json':
            result = {
                'ip': self.anonymize_ip(self.args.ip),
                'total_requests': detail['total'],
                'status_distribution': {},
                'top_paths': [],
                'top_user_agents': []
            }

            for status, cnt in detail['statuses'].most_common():
                cls = classify_status_for_display(status).split()[0]
                result['status_distribution'][status] = {
                    'count': cnt,
                    'class': cls
                }

            for path, cnt in detail['paths'].most_common(10):
                result['top_paths'].append({
                    'path': path,
                    'count': cnt
                })

            for ua, cnt in detail['uas'].most_common(3):
                display_ua = ua[:60] + '...' if len(ua) > 60 else ua
                result['top_user_agents'].append({
                    'user_agent': display_ua,
                    'count': cnt
                })

            print(json.dumps(result, ensure_ascii=False, indent=2))
        elif self.output_format == 'csv':
            writer = csv.writer(sys.stdout)
            writer.writerow(['type', 'value', 'count'])

            # çŠ¶æ€ç åˆ†å¸ƒ
            for status, cnt in detail['statuses'].most_common():
                cls = classify_status_for_display(status).split()[0]
                writer.writerow(['status', f"{status} ({cls})", cnt])

            # Top Paths
            for path, cnt in detail['paths'].most_common(10):
                writer.writerow(['path', path, cnt])

            # Top User-Agents
            for ua, cnt in detail['uas'].most_common(3):
                display_ua = ua[:60] + '...' if len(ua) > 60 else ua
                writer.writerow(['user_agent', display_ua, cnt])
        else:  # text format
            print(f"ğŸ” è¯¦ç»†åˆ†æ IP: {self.anonymize_ip(self.args.ip)}")
            print(f"æ€»è¯·æ±‚æ¬¡æ•°: {detail['total']}")

            print("\nğŸ“Š çŠ¶æ€ç åˆ†å¸ƒ:")
            for status, cnt in detail['statuses'].most_common():
                cls = classify_status_for_display(status).split()[0]
                print(f"  - {status} ({cls}): {cnt} æ¬¡")

            print(f"\nğŸš€ Top {min(10, len(detail['paths']))} è®¿é—®è·¯å¾„:")
            for path, cnt in detail['paths'].most_common(10):
                print(f"  - {path}: {cnt} æ¬¡")

            print(f"\nğŸ“± Top User-Agent (å‰ 3):")
            for ua, cnt in detail['uas'].most_common(3):
                display_ua = ua[:60] + '...' if len(ua) > 60 else ua
                print(f"  - {display_ua}: {cnt} æ¬¡")

    def _global_analysis(self):
        """å…¨å±€åˆ†æ"""
        if self.output_format == 'json':
            result = {
                'summary': {
                    'total_lines': self.total_lines,
                    'filtered_lines': self.filtered_lines
                },
                'status_classes': {},
                'ip_groups': {},
                'top_ips': [],
                'top_paths': []
            }

            # çŠ¶æ€ç åˆ†ç±»ç»Ÿè®¡
            for cls, count in self.status_class_counter.most_common():
                result['status_classes'][cls] = count

            # IPåˆ†ç»„ç»Ÿè®¡
            ip_groups = self._group_ips_by_request_count()
            for group, count in ip_groups.items():
                result['ip_groups'][group] = count

            # Top IPs
            for i, (ip, count) in enumerate(self.ip_counter.most_common(self.args.top), 1):
                result['top_ips'].append({
                    'rank': i,
                    'ip': self.anonymize_ip(ip),
                    'requests': count
                })

            # Top Paths
            for i, (path, count) in enumerate(self.path_counter.most_common(self.args.top), 1):
                result['top_paths'].append({
                    'rank': i,
                    'path': path,
                    'requests': count
                })

            print(json.dumps(result, ensure_ascii=False, indent=2))
        elif self.output_format == 'csv':
            writer = csv.writer(sys.stdout)

            # çŠ¶æ€ç åˆ†ç±»ç»Ÿè®¡
            writer.writerow(['section', 'item', 'count'])
            for cls, count in self.status_class_counter.most_common():
                writer.writerow(['status_class', cls, count])

            # IPåˆ†ç»„ç»Ÿè®¡
            ip_groups = self._group_ips_by_request_count()
            for group, count in ip_groups.items():
                writer.writerow(['ip_group', group, count])

            # Top IPs
            writer.writerow([])  # ç©ºè¡Œåˆ†éš”
            writer.writerow(['rank', 'ip', 'requests'])
            for i, (ip, count) in enumerate(self.ip_counter.most_common(self.args.top), 1):
                writer.writerow([i, self.anonymize_ip(ip), count])

            # Top Paths
            writer.writerow([])  # ç©ºè¡Œåˆ†éš”
            writer.writerow(['rank', 'path', 'requests'])
            for i, (path, count) in enumerate(self.path_counter.most_common(self.args.top), 1):
                writer.writerow([i, path, count])
        else:  # text format
            print(f"ğŸ“Š å…¨èƒ½æ—¥å¿—åˆ†ææŠ¥å‘Šï¼ˆTop {self.args.top}ï¼‰\n")
            print("=" * 70)

            print("ğŸš¦ çŠ¶æ€ç åˆ†ç±»ç»Ÿè®¡:")
            for cls, count in self.status_class_counter.most_common():
                print(f"  {cls:<20} â†’ {count:>8} æ¬¡")
            print()

            groups = self._group_ips_by_request_count()
            print("ğŸ“ IP è¯·æ±‚é‡åˆ†ç»„:")
            for group, count in groups.items():
                print(f"  {group:<25} â†’ {count:>6} ä¸ª IP")
            print()

            print(f"ğŸ” Top {self.args.top} è¯·æ±‚ IP:")
            for i, (ip, count) in enumerate(self.ip_counter.most_common(self.args.top), 1):
                print(f"{i:2}. {self.anonymize_ip(ip):<15} â†’ {count:>8} æ¬¡")
            print()

            print(f"ğŸš€ Top {self.args.top} è®¿é—®è·¯å¾„:")
            for i, (path, count) in enumerate(self.path_counter.most_common(self.args.top), 1):
                print(f"{i:2}. {path:<40} â†’ {count:>8} æ¬¡")

    def _group_ips_by_request_count(self, high=None, mid=None):
        """æ ¹æ®è¯·æ±‚æ¬¡æ•°å¯¹IPè¿›è¡Œåˆ†ç»„"""
        if high is None:
            high = self.args.high_freq
        if mid is None:
            mid = self.args.mid_freq

        groups = {
            f'è¶…é«˜é¢‘ (â‰¥{high:,})': 0,
            f'é«˜é¢‘ ({mid:,} ~ {high - 1:,})': 0,
            f'ä¸­é¢‘ (100 ~ {mid - 1:,})': 0,
            'ä½é¢‘ (<100)': 0
        }
        for count in self.ip_counter.values():
            if count >= high:
                groups[f'è¶…é«˜é¢‘ (â‰¥{high:,})'] += 1
            elif count >= mid:
                groups[f'é«˜é¢‘ ({mid:,} ~ {high - 1:,})'] += 1
            elif count >= 100:
                groups[f'ä¸­é¢‘ (100 ~ {mid - 1:,})'] += 1
            else:
                groups['ä½é¢‘ (<100)'] += 1
        return groups


def parse_log_time(time_str):
    """è§£æ Nginx æ—¶é—´æˆ³"""
    try:
        return datetime.strptime(time_str, TIME_FORMAT)
    except ValueError:
        if len(time_str) >= 5 and time_str[-5] not in ('+', '-'):
            # å°è¯•ä¿®å¤æ—¶åŒºå‰æ— ç©ºæ ¼çš„æƒ…å†µï¼Œå¦‚ "10/Dec/2025:10:30:45+0800"
            fixed = time_str[:-5] + ' ' + time_str[-5:]
            return datetime.strptime(fixed, TIME_FORMAT)
        raise


def get_time_window(args):
    """è¿”å› (start, end) datetime èŒƒå›´ï¼ˆawareï¼‰"""
    now = datetime.now().astimezone()
    if args.today:
        start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        return start, now
    if args.last:
        unit = args.last[-1].lower()
        value = int(args.last[:-1])
        delta = timedelta(hours=value) if unit == 'h' else timedelta(days=value)
        start = now - delta
        return start, now
    return None, None


def open_log_file(filepath):
    """æ™ºèƒ½æ‰“å¼€ .log æˆ– .log.gz æ–‡ä»¶"""
    try:
        if filepath.endswith('.gz'):
            return gzip.open(filepath, 'rt', encoding='utf-8', errors='ignore')
        else:
            return open(filepath, 'r', encoding='utf-8', errors='ignore')
    except PermissionError:
        raise Exception("Permission denied")
    except FileNotFoundError:
        raise Exception("File not found")
    except Exception as e:
        raise Exception(f"Unknown error opening file: {str(e)}")


@lru_cache(maxsize=1024)
def classify_status_for_display(status):
    """å¸¦ç¼“å­˜çš„çŠ¶æ€ç æ˜¾ç¤ºæ˜ å°„"""
    s = int(status)
    if 200 <= s < 300:
        return "âœ… 2xx æˆåŠŸ"
    elif 300 <= s < 400:
        return "ğŸ”€ 3xx é‡å®šå‘"
    elif 400 <= s < 500:
        return "âš ï¸ 4xx å®¢æˆ·ç«¯é”™è¯¯"
    elif 500 <= s < 600:
        return "ğŸ’¥ 5xx æœåŠ¡ç«¯é”™è¯¯"
    else:
        return "â“ å…¶ä»–"


def classify_status_code_class(status):
    """åˆ†ç±»çŠ¶æ€ç ç±»åˆ«"""
    s = int(status)
    if 200 <= s < 300:
        return "2xx"
    elif 300 <= s < 400:
        return "3xx"
    elif 400 <= s < 500:
        return "4xx"
    elif 500 <= s < 600:
        return "5xx"
    else:
        return "other"


def is_sensitive_path(path, sensitive_paths_set):
    """åˆ¤æ–­æ˜¯å¦ä¸ºæ•æ„Ÿè·¯å¾„"""
    clean = path.split('?')[0].rstrip('/')
    for sp in sensitive_paths_set:
        # æ›´ä¸¥æ ¼çš„è·¯å¾„åŒ¹é…è§„åˆ™ï¼Œé˜²æ­¢è¯¯å‘½ä¸­ç±»ä¼¼ /admin -> /administrator
        if clean == sp or (sp.endswith('/') and clean.startswith(sp)):
            return True
    return False


def parse_sensitive_paths(paths_str):
    """è§£ææ•æ„Ÿè·¯å¾„åˆ—è¡¨"""
    if not paths_str:
        return DEFAULT_SENSITIVE_PATHS
    parsed = set()
    for p in paths_str.split(','):
        stripped = p.strip()
        if stripped.startswith('/'):
            parsed.add(stripped.rstrip('/'))
        else:
            print(f"âš ï¸ å¿½ç•¥éæ³•è·¯å¾„: {stripped} ï¼ˆå¿…é¡»ä»¥ '/' å¼€å¤´ï¼‰")
    return parsed


def main():
    parser = argparse.ArgumentParser(
        description="å…¨èƒ½ Nginx æ—¥å¿—åˆ†æå™¨ï¼ˆæ”¯æŒå¤šæ–‡ä»¶ã€æ—¶é—´çª—å£ã€GZ å‹ç¼©ï¼‰",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("logfiles", nargs='+', help="ä¸€ä¸ªæˆ–å¤šä¸ªæ—¥å¿—æ–‡ä»¶ï¼ˆæ”¯æŒ .gzï¼‰")
    parser.add_argument("--top", type=int, default=20, help="Top N æ•°é‡ï¼ˆé»˜è®¤ 20ï¼‰")

    time_group = parser.add_mutually_exclusive_group()
    time_group.add_argument("--last", type=str, help="æœ€è¿‘æ—¶é—´ï¼Œå¦‚ '1h', '24h', '7d'")
    time_group.add_argument("--today", action="store_true", help="ä»…ä»Šå¤©")

    query_group = parser.add_mutually_exclusive_group()
    query_group.add_argument("--ip", help="æŸ¥è¯¢ç‰¹å®š IP")
    query_group.add_argument("--path", help="æŸ¥è¯¢ç‰¹å®šè·¯å¾„")
    query_group.add_argument("--group-by", choices=["freq-status"], help="æŒ‰é¢‘ç‡+çŠ¶æ€åˆ†ç»„")

    parser.add_argument("--high-freq", type=int, default=1000, help="é«˜é¢‘é˜ˆå€¼ï¼ˆé»˜è®¤ 1000ï¼‰")
    parser.add_argument("--mid-freq", type=int, default=100, help="ä¸­é¢‘é˜ˆå€¼ï¼ˆé»˜è®¤ 100ï¼‰")
    parser.add_argument("--error-rate", type=float, default=0.5, help="é”™è¯¯ç‡é˜ˆå€¼ï¼ˆ0.0~1.0ï¼‰")
    parser.add_argument("--sensitive-ratio", type=float, default=0.5, help="æ•æ„Ÿè·¯å¾„å æ¯”é˜ˆå€¼")
    parser.add_argument("--sensitive-paths", type=str, help="è‡ªå®šä¹‰æ•æ„Ÿè·¯å¾„ï¼ˆé€—å·åˆ†éš”ï¼‰")

    # æ–°å¢åŠŸèƒ½å‚æ•°
    parser.add_argument("--output-format", choices=["text", "json", "csv"], default="text",
                        help="è¾“å‡ºæ ¼å¼(text/json/csv)")
    parser.add_argument("--filter-status", choices=["2xx", "3xx", "4xx", "5xx"], help="åªåˆ†æç‰¹å®šçŠ¶æ€ç ç±»åˆ«")
    parser.add_argument("--anonymize-ip", action="store_true", help="è¾“å‡ºæ—¶éšè—IPæœ€åä¸€æ®µ")

    args = parser.parse_args()

    args.sensitive_paths = parse_sensitive_paths(args.sensitive_paths)

    if args.last:
        if not re.match(r'^\d+[hd]$', args.last, re.IGNORECASE):
            parser.error("--last å¿…é¡»æ˜¯æ•°å­—+h/dï¼Œå¦‚ '1h', '24h', '7d'")

    if not (0.0 <= args.error_rate <= 1.0):
        parser.error("--error-rate å¿…é¡»åœ¨ 0.0 ~ 1.0 ä¹‹é—´")
    if not (0.0 <= args.sensitive_ratio <= 1.0):
        parser.error("--sensitive-ratio å¿…é¡»åœ¨ 0.0 ~ 1.0 ä¹‹é—´")

    # æ‰§è¡Œåˆ†æ
    analyzer = LogAnalyzer(args)
    analyzer.analyze()


if __name__ == '__main__':
    main()