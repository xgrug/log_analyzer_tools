#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿäº§ç¯å¢ƒé™æµç­–ç•¥åˆ†æä¸æ¨èå·¥å…· v2.0
ä¸»è¦ä¼˜åŒ–:
- å†…å­˜ä¼˜åŒ–: æµå¼å¤„ç†å¤§æ–‡ä»¶
- æ€§èƒ½æå‡: å¹¶è¡Œå¤„ç†ã€ç¼“å­˜ä¼˜åŒ–
- åŠŸèƒ½å¢å¼º: å¼‚å¸¸æ£€æµ‹ã€è¶‹åŠ¿åˆ†æã€A/Bæµ‹è¯•æ¨¡æ‹Ÿ
- ç”Ÿäº§é€‚é…: æ›´ä¸°å¯Œçš„æŠ¥å‘Šã€å‘Šè­¦å»ºè®®
"""

import re
import gzip
import mmap
from collections import defaultdict, Counter, deque
from datetime import datetime, timedelta
import argparse
import os
import sys
import json
from typing import List, Set, Optional, Callable, Tuple, Dict, Any, Iterator
import ipaddress
from dataclasses import dataclass, asdict
from concurrent.futures import ProcessPoolExecutor, as_completed
import bisect
import hashlib

# ========================
# é…ç½®ä¸å¸¸é‡
# ========================
DEFAULT_WINDOW_SEC = 10
DEFAULT_MAX_REQ = 40
ANALYSIS_WINDOWS = [1, 5, 10, 30, 60]
MAX_URI_TRACK = 100_000  # æé«˜åˆ° 10 ä¸‡
CHUNK_SIZE = 100_000  # åˆ†å—å¤„ç†å¤§å°
MAX_MEMORY_RECORDS = 5_000_000  # å†…å­˜è®°å½•ä¸Šé™

DEFAULT_EXCLUDE_UA_KEYWORDS = [
    'bot', 'spider', 'crawler', 'scan', 'python-requests',
    'curl', 'wget', 'httpclient', 'go-http', 'java/', 'masscan',
    'headless', 'selenium', 'phantom'
]

DEFAULT_LOG_FORMAT = '$remote_addr - - [$time_local] "$request" $status $body_bytes_sent "$http_referer" "$http_user_agent"'


# ========================
# æ•°æ®ç±»
# ========================
@dataclass
class RequestRecord:
    """è¯·æ±‚è®°å½•"""
    ip: str
    timestamp: datetime
    path: str
    status: int


@dataclass
class BurstAnalysis:
    """çªå‘åˆ†æç»“æœ"""
    window_sec: int
    max_burst: int
    p50: int
    p90: int
    p95: int
    p99: int
    avg: float


@dataclass
class AnomalyAlert:
    """å¼‚å¸¸å‘Šè­¦"""
    type: str  # 'spike', 'sustained_high', 'distributed_attack'
    severity: str  # 'low', 'medium', 'high', 'critical'
    ip: Optional[str]
    description: str
    metric_value: float
    threshold: float


# ========================
# æ—¥å¿—è§£æå™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# ========================
class OptimizedLogParser:
    """ä¼˜åŒ–çš„æ—¥å¿—è§£æå™¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œç¼“å­˜"""

    def __init__(self, log_format: str):
        self.pattern = self._compile_pattern(log_format)
        self.has_ua = '$http_user_agent' in log_format
        self._cache = {}  # ç¼“å­˜è§£æç»“æœ
        self._parse_failures = 0

    def _compile_pattern(self, log_format: str) -> re.Pattern:
        """ç¼–è¯‘æ—¥å¿—æ ¼å¼ä¸ºæ­£åˆ™è¡¨è¾¾å¼"""

        # å¦‚æœæ˜¯é»˜è®¤æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨é¢„å®šä¹‰çš„æ­£åˆ™
        if log_format == DEFAULT_LOG_FORMAT:
            pattern = (
                r'(?P<ip>\S+)\s+-\s+-\s+'
                r'\[(?P<time>[^\]]+)\]\s+'
                r'"(?P<method>\S+)\s+(?P<path>\S+)\s+(?P<protocol>[^"]+)"\s+'
                r'(?P<status>\d+)\s+'
                r'(?P<bytes>\S+)\s+'
                r'"(?P<referer>[^"]*)"\s+'
                r'"(?P<user_agent>[^"]*)"'
            )
            try:
                compiled = re.compile(pattern)
                print(f"[DEBUG] ä½¿ç”¨é»˜è®¤æ—¥å¿—æ ¼å¼æ­£åˆ™", file=sys.stderr)
                return compiled
            except re.error as e:
                print(f"[ERROR] æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘å¤±è´¥: {e}", file=sys.stderr)
                sys.exit(1)

        # è‡ªå®šä¹‰æ ¼å¼å¤„ç†
        # å®šä¹‰å˜é‡åˆ°æ­£åˆ™çš„æ˜ å°„
        var_patterns = {
            '$remote_addr': r'(?P<ip>\S+)',
            '$time_local': r'(?P<time>[^\]]+)',
            '$request': r'"(?P<method>\S+)\s+(?P<path>\S+)\s+(?P<protocol>[^"]+)"',
            '$status': r'(?P<status>\d+)',
            '$body_bytes_sent': r'(?P<bytes>\S+)',
            '$http_referer': r'"(?P<referer>[^"]*)"',
            '$http_user_agent': r'"(?P<user_agent>[^"]*)"',
            '$request_time': r'(?P<req_time>\S+)',
        }

        # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼
        pattern = log_format

        # æ›¿æ¢å˜é‡ä¸ºæ­£åˆ™
        for var, regex in var_patterns.items():
            pattern = pattern.replace(var, regex)

        # è½¬ä¹‰æ–¹æ‹¬å·
        pattern = pattern.replace('[', r'\[').replace(']', r'\]')

        # å¤„ç†ç©ºæ ¼å’Œè¿å­—ç¬¦
        pattern = re.sub(r'\s+', r'\\s+', pattern)

        try:
            compiled = re.compile(pattern)
            print(f"[DEBUG] è‡ªå®šä¹‰æ ¼å¼æ­£åˆ™: {pattern[:150]}...", file=sys.stderr)
            return compiled
        except re.error as e:
            print(f"[ERROR] æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘å¤±è´¥: {e}", file=sys.stderr)
            print(f"[ERROR] æ¨¡å¼: {pattern}", file=sys.stderr)
            sys.exit(1)

    def parse(self, line: str) -> Optional[Dict[str, str]]:
        """è§£æå•è¡Œæ—¥å¿—"""
        line = line.strip()
        if not line:
            return None

        # ç®€å•ç¼“å­˜
        line_hash = hash(line[:100])
        if line_hash in self._cache:
            return self._cache[line_hash]

        match = self.pattern.match(line)  # ä½¿ç”¨ match è€Œä¸æ˜¯ search
        if not match:
            self._parse_failures += 1
            # åªæ‰“å°å‰å‡ ä¸ªå¤±è´¥çš„æ ·ä¾‹
            if self._parse_failures <= 5:
                print(f"[DEBUG] è§£æå¤±è´¥ #{self._parse_failures}: {line[:200]}", file=sys.stderr)
            return None

        result = match.groupdict()

        # éªŒè¯å¿…éœ€å­—æ®µ
        if not result.get('ip') or not result.get('status') or not result.get('time'):
            self._parse_failures += 1
            return None

        if len(self._cache) < 10000:
            self._cache[line_hash] = result

        return result

    def get_stats(self) -> Dict[str, int]:
        """è·å–è§£æç»Ÿè®¡"""
        return {
            'cache_size': len(self._cache),
            'parse_failures': self._parse_failures
        }


def parse_log_time(time_str: str) -> datetime:
    """è§£æ Nginx æ—¶é—´æ ¼å¼ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
    time_str = time_str.strip()

    # å°è¯•å¤šç§å¸¸è§æ ¼å¼
    formats = [
        "%d/%b/%Y:%H:%M:%S %z",  # æ ‡å‡† Nginx: 01/Jan/2024:12:00:00 +0800
        "%d/%b/%Y:%H:%M:%S",  # æ— æ—¶åŒº
        "%Y-%m-%d %H:%M:%S",  # ISO æ ¼å¼
        "%d/%b/%Y %H:%M:%S",  # ç©ºæ ¼åˆ†éš”
    ]

    for fmt in formats:
        try:
            return datetime.strptime(time_str, fmt)
        except ValueError:
            continue

    # å°è¯•æ‰‹åŠ¨å¤„ç†æ—¶åŒº
    parts = time_str.split()
    if len(parts) >= 2:
        date_part = parts[0]
        tz_part = parts[1] if len(parts) > 1 else None

        for fmt in ["%d/%b/%Y:%H:%M:%S", "%d/%b/%Y %H:%M:%S"]:
            try:
                dt = datetime.strptime(date_part, fmt)
                if tz_part:
                    # ç®€å•å¤„ç†æ—¶åŒºï¼ˆå¦‚ +0800ï¼‰
                    try:
                        return datetime.strptime(f"{date_part} {tz_part}", f"{fmt} %z")
                    except:
                        return dt
                return dt
            except ValueError:
                continue

    raise ValueError(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}")


def open_log_file(filepath: str):
    """æ™ºèƒ½æ‰“å¼€æ—¥å¿—æ–‡ä»¶ï¼ˆæ”¯æŒå‹ç¼©ï¼‰"""
    if filepath.endswith('.gz'):
        return gzip.open(filepath, 'rt', encoding='utf-8', errors='replace')
    return open(filepath, 'r', encoding='utf-8', errors='replace')


def align_to_window(dt: datetime, window_sec: int) -> datetime:
    """å¯¹é½åˆ°æ—¶é—´çª—å£"""
    ts = int(dt.timestamp())
    aligned = (ts // window_sec) * window_sec
    return datetime.fromtimestamp(aligned, tz=dt.tzinfo or None)


# ========================
# è¿‡æ»¤å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# ========================
class IPFilter:
    """IP è¿‡æ»¤å™¨ï¼ˆæ”¯æŒ CIDR å’Œå¿«é€ŸæŸ¥æ‰¾ï¼‰"""

    def __init__(self, ip_list: List[str], exclude_file: Optional[str] = None):
        self.networks = set()
        self.single_ips = set()
        self._load_ips(ip_list, exclude_file)

    def _load_ips(self, ip_list: List[str], exclude_file: Optional[str]):
        items = list(ip_list)
        if exclude_file and os.path.exists(exclude_file):
            with open(exclude_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        items.append(line)

        for item in items:
            item = item.strip()
            if not item:
                continue
            try:
                if '/' in item:
                    net = ipaddress.IPv4Network(item, strict=False)
                    self.networks.add(net)
                else:
                    # å• IP ç›´æ¥å­˜å‚¨ï¼Œé¿å…ç½‘ç»œå¯¹è±¡å¼€é”€
                    self.single_ips.add(item)
            except Exception as e:
                print(f"[WARN] æ— æ•ˆ IP: {item} ({e})", file=sys.stderr)

    def is_excluded(self, ip_str: str) -> bool:
        """æ£€æŸ¥ IP æ˜¯å¦è¢«æ’é™¤"""
        if ip_str in self.single_ips:
            return True

        if not self.networks:
            return False

        try:
            ip = ipaddress.IPv4Address(ip_str)
            for net in self.networks:
                if ip in net:
                    return True
        except Exception:
            pass

        return False


class StatusFilter:
    """HTTP çŠ¶æ€ç è¿‡æ»¤å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""

    def __init__(self, include_pattern: str, exclude_pattern: Optional[str]):
        self.include_codes = self._parse_pattern(include_pattern)
        self.exclude_codes = self._parse_pattern(exclude_pattern) if exclude_pattern else set()

        # é¢„å®šä¹‰çš„é”™è¯¯çŠ¶æ€ç ï¼ˆä¼šè‡ªåŠ¨æ’é™¤ï¼Œé™¤éæ˜ç¡®åŒ…å«ï¼‰
        self.error_codes = set(range(400, 600))  # 4xx, 5xx å…¨éƒ¨è§†ä¸ºé”™è¯¯

        # å¦‚æœç”¨æˆ·æ˜ç¡®åŒ…å«äº†é”™è¯¯ç ï¼Œåˆ™ä¸è‡ªåŠ¨æ’é™¤
        self.auto_exclude_errors = not (self.include_codes & self.error_codes)

    def _parse_pattern(self, pattern: str) -> Set[int]:
        """è§£æçŠ¶æ€ç æ¨¡å¼ï¼ˆå¦‚ 2**,3**,200,301ï¼‰"""
        codes = set()
        if not pattern:
            return codes

        for part in pattern.split(','):
            part = part.strip()
            if part.endswith('**'):
                # èŒƒå›´åŒ¹é…
                prefix = int(part[0])
                codes.update(range(prefix * 100, (prefix + 1) * 100))
            elif part.endswith('*'):
                # åä½åŒ¹é…ï¼Œå¦‚ 20* åŒ¹é… 200-209
                prefix = int(part[:-1])
                codes.update(range(prefix * 10, (prefix + 1) * 10))
            elif '-' in part:
                # èŒƒå›´åŒ¹é…ï¼Œå¦‚ 200-299
                start, end = part.split('-')
                codes.update(range(int(start), int(end) + 1))
            elif part.isdigit():
                codes.add(int(part))

        return codes

    def accept(self, status_code: int) -> bool:
        """åˆ¤æ–­çŠ¶æ€ç æ˜¯å¦æ¥å—"""
        # ä¼˜å…ˆæ£€æŸ¥æ’é™¤åˆ—è¡¨
        if status_code in self.exclude_codes:
            return False

        # è‡ªåŠ¨æ’é™¤é”™è¯¯ç ï¼ˆé™¤éç”¨æˆ·æ˜ç¡®åŒ…å«ï¼‰
        if self.auto_exclude_errors and status_code in self.error_codes:
            return False

        # æ£€æŸ¥åŒ…å«åˆ—è¡¨
        return status_code in self.include_codes

    def get_filter_info(self) -> Dict[str, Any]:
        """è·å–è¿‡æ»¤å™¨ä¿¡æ¯"""
        return {
            'include_codes_count': len(self.include_codes),
            'exclude_codes_count': len(self.exclude_codes),
            'auto_exclude_errors': self.auto_exclude_errors,
            'example_included': sorted(list(self.include_codes))[:10],
            'example_excluded': sorted(list(self.exclude_codes))[:10]
        }


class UAFilter:
    """User-Agent è¿‡æ»¤å™¨ï¼ˆä¼˜åŒ–åŒ¹é…ï¼‰"""

    def __init__(self, exclude_keywords: List[str]):
        self.keywords = [kw.lower() for kw in exclude_keywords]

    def should_exclude(self, ua: str) -> bool:
        """åˆ¤æ–­ UA æ˜¯å¦åº”è¯¥æ’é™¤"""
        if not ua or not self.keywords:
            return False

        ua_lower = ua.lower()
        return any(kw in ua_lower for kw in self.keywords)


# ========================
# æµå¼è®°å½•æå–ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰
# ========================
def stream_records(
        logfiles: List[str],
        ip_filter: IPFilter,
        status_filter: StatusFilter,
        ua_filter: UAFilter,
        log_parser: OptimizedLogParser,
        time_range: Optional[Tuple[datetime, datetime]] = None,
        max_records: int = MAX_MEMORY_RECORDS
) -> Iterator[RequestRecord]:
    """æµå¼æå–è®°å½•ï¼ˆç”Ÿæˆå™¨ï¼ŒèŠ‚çœå†…å­˜ï¼‰"""

    total_raw = 0
    total_kept = 0
    parse_errors = 0
    filter_stats = {
        'ip_excluded': 0,
        'status_excluded': 0,
        'ua_excluded': 0,
        'time_excluded': 0,
        'parse_failed': 0
    }

    # çŠ¶æ€ç åˆ†å¸ƒç»Ÿè®¡ï¼ˆç”¨äºæ˜¾ç¤ºé”™è¯¯å½±å“ï¼‰
    status_distribution = Counter()

    for logfile in logfiles:
        if not os.path.exists(logfile):
            print(f"[WARN] æ–‡ä»¶ä¸å­˜åœ¨: {logfile}", file=sys.stderr)
            continue

        print(f"[INFO] å¤„ç†æ–‡ä»¶: {logfile}", file=sys.stderr)

        with open_log_file(logfile) as f:
            for line in f:
                total_raw += 1

                # å®šæœŸè¾“å‡ºè¿›åº¦
                if total_raw % 50000 == 0:
                    print(f"[INFO] å·²å¤„ç† {total_raw:,} è¡Œï¼Œä¿ç•™ {total_kept:,} æ¡ "
                          f"(è§£æå¤±è´¥: {filter_stats['parse_failed']}, "
                          f"IPè¿‡æ»¤: {filter_stats['ip_excluded']}, "
                          f"çŠ¶æ€ç è¿‡æ»¤: {filter_stats['status_excluded']})",
                          file=sys.stderr)

                parsed = log_parser.parse(line)
                if not parsed:
                    filter_stats['parse_failed'] += 1
                    continue

                # IP è¿‡æ»¤
                ip = parsed.get('ip', '')
                if not ip or ip == '-':
                    filter_stats['parse_failed'] += 1
                    continue

                if ip_filter.is_excluded(ip):
                    filter_stats['ip_excluded'] += 1
                    continue

                # çŠ¶æ€ç è¿‡æ»¤
                status_str = parsed.get('status', '')
                if not status_str or not status_str.isdigit():
                    filter_stats['parse_failed'] += 1
                    continue

                status_code = int(status_str)

                # ç»Ÿè®¡çŠ¶æ€ç åˆ†å¸ƒï¼ˆæ‰€æœ‰çŠ¶æ€ç ï¼‰
                status_distribution[status_code] += 1

                if not status_filter.accept(status_code):
                    filter_stats['status_excluded'] += 1
                    continue

                # UA è¿‡æ»¤
                ua = parsed.get('user_agent', '') if log_parser.has_ua else ''
                if ua_filter.should_exclude(ua):
                    filter_stats['ua_excluded'] += 1
                    continue

                # æ—¶é—´è§£æ
                try:
                    log_time = parse_log_time(parsed['time'])
                except Exception as e:
                    filter_stats['parse_failed'] += 1
                    if parse_errors < 3:
                        print(f"[DEBUG] æ—¶é—´è§£æå¤±è´¥: {parsed.get('time', 'N/A')} - {e}", file=sys.stderr)
                    parse_errors += 1
                    continue

                # æ—¶é—´èŒƒå›´è¿‡æ»¤
                if time_range:
                    start, end = time_range
                    if log_time < start or log_time > end:
                        filter_stats['time_excluded'] += 1
                        continue

                path = parsed.get('path', '/')

                total_kept += 1
                yield RequestRecord(ip, log_time, path, status_code)

                # å®‰å…¨ä¸Šé™
                if total_kept >= max_records:
                    print(f"[WARN] å·²è¾¾åˆ°è®°å½•ä¸Šé™ {max_records:,}ï¼Œåœæ­¢åŠ è½½", file=sys.stderr)
                    break

    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n[INFO] ========== å¤„ç†ç»Ÿè®¡ ==========", file=sys.stderr)
    print(f"[INFO] æ€»è¡Œæ•°: {total_raw:,}", file=sys.stderr)
    print(f"[INFO] æœ‰æ•ˆè¯·æ±‚: {total_kept:,}", file=sys.stderr)
    print(f"[INFO] è¿‡æ»¤ç»Ÿè®¡:", file=sys.stderr)
    print(f"[INFO]   - è§£æå¤±è´¥: {filter_stats['parse_failed']:,}", file=sys.stderr)
    print(f"[INFO]   - IP è¿‡æ»¤: {filter_stats['ip_excluded']:,}", file=sys.stderr)
    print(f"[INFO]   - çŠ¶æ€ç è¿‡æ»¤: {filter_stats['status_excluded']:,}", file=sys.stderr)
    print(f"[INFO]   - UA è¿‡æ»¤: {filter_stats['ua_excluded']:,}", file=sys.stderr)
    print(f"[INFO]   - æ—¶é—´è¿‡æ»¤: {filter_stats['time_excluded']:,}", file=sys.stderr)

    # çŠ¶æ€ç åˆ†å¸ƒåˆ†æ
    print(f"\n[INFO] ========== çŠ¶æ€ç åˆ†å¸ƒ ==========", file=sys.stderr)

    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    status_by_category = {
        '2xx (æˆåŠŸ)': 0,
        '3xx (é‡å®šå‘)': 0,
        '4xx (å®¢æˆ·ç«¯é”™è¯¯)': 0,
        '5xx (æœåŠ¡ç«¯é”™è¯¯)': 0,
        'å…¶ä»–': 0
    }

    for status, count in status_distribution.items():
        if 200 <= status < 300:
            status_by_category['2xx (æˆåŠŸ)'] += count
        elif 300 <= status < 400:
            status_by_category['3xx (é‡å®šå‘)'] += count
        elif 400 <= status < 500:
            status_by_category['4xx (å®¢æˆ·ç«¯é”™è¯¯)'] += count
        elif 500 <= status < 600:
            status_by_category['5xx (æœåŠ¡ç«¯é”™è¯¯)'] += count
        else:
            status_by_category['å…¶ä»–'] += count

    total_status = sum(status_by_category.values())
    for category, count in status_by_category.items():
        if count > 0:
            percentage = count / total_status * 100
            print(f"[INFO]   {category}: {count:,} ({percentage:.2f}%)", file=sys.stderr)

    # Top é”™è¯¯çŠ¶æ€ç 
    error_codes = [(code, count) for code, count in status_distribution.items() if code >= 400]
    if error_codes:
        error_codes.sort(key=lambda x: x[1], reverse=True)
        print(f"\n[INFO] ========== Top 5 é”™è¯¯çŠ¶æ€ç  ==========", file=sys.stderr)
        for code, count in error_codes[:5]:
            percentage = count / total_status * 100
            print(f"[INFO]   {code}: {count:,} ({percentage:.2f}%)", file=sys.stderr)

        total_errors = sum(count for _, count in error_codes)
        error_rate = total_errors / total_status * 100
        print(f"\n[INFO] æ€»é”™è¯¯ç‡: {error_rate:.2f}%", file=sys.stderr)

        if error_rate > 10:
            print(f"[WARN] âš ï¸  é”™è¯¯ç‡è¾ƒé«˜ï¼ˆ>{error_rate:.1f}%ï¼‰ï¼Œè¿™äº›é”™è¯¯è¯·æ±‚å·²è‡ªåŠ¨æ’é™¤ï¼Œä¸å½±å“é™æµç­–ç•¥", file=sys.stderr)
        elif error_rate > 5:
            print(f"[INFO] â„¹ï¸  é”™è¯¯ç‡é€‚ä¸­ï¼ˆ{error_rate:.1f}%ï¼‰ï¼Œå·²è‡ªåŠ¨æ’é™¤", file=sys.stderr)
        else:
            print(f"[INFO] âœ… é”™è¯¯ç‡è¾ƒä½ï¼ˆ{error_rate:.1f}%ï¼‰", file=sys.stderr)

    # æ‰“å°è§£æå™¨ç»Ÿè®¡
    parser_stats = log_parser.get_stats()
    print(f"\n[INFO] è§£æå™¨ç¼“å­˜å¤§å°: {parser_stats['cache_size']}", file=sys.stderr)


# ========================
# æ ¸å¿ƒåˆ†æå¼•æ“
# ========================
class RateLimitAnalyzer:
    """é™æµåˆ†æå¼•æ“"""

    def __init__(self, records: List[RequestRecord]):
        self.records = records
        self.ip_timings = defaultdict(list)
        self.uri_counter = Counter()
        self.uri_timings = defaultdict(list)

        self._build_indexes()

    def _build_indexes(self):
        """æ„å»ºç´¢å¼•ï¼ˆä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ï¼‰"""
        print("[INFO] æ„å»ºåˆ†æç´¢å¼•...", file=sys.stderr)

        for rec in self.records:
            self.ip_timings[rec.ip].append(rec.timestamp)
            self.uri_counter[rec.path] += 1

            if len(self.uri_timings) < MAX_URI_TRACK:
                self.uri_timings[rec.path].append(rec.timestamp)

        # æ’åºä»¥åŠ é€Ÿåç»­åˆ†æ
        for ip in self.ip_timings:
            self.ip_timings[ip].sort()

        for uri in self.uri_timings:
            self.uri_timings[uri].sort()

    def evaluate_policy(self, window_sec: int, max_req: int) -> Dict[str, Any]:
        """è¯„ä¼°å½“å‰é™æµç­–ç•¥"""
        ip_window_counter = defaultdict(Counter)

        for ip, timings in self.ip_timings.items():
            for t in timings:
                window_start = align_to_window(t, window_sec)
                ip_window_counter[ip][window_start] += 1

        violations = []
        all_bursts = []
        violation_ips = set()

        for ip, windows in ip_window_counter.items():
            for cnt in windows.values():
                all_bursts.append(cnt)
                if cnt > max_req:
                    violations.append(cnt)
                    violation_ips.add(ip)

        return {
            'window_seconds': window_sec,
            'current_limit': max_req,
            'total_requests': len(self.records),
            'total_unique_ips': len(self.ip_timings),
            'violations_count': len(violations),
            'violation_ips_count': len(violation_ips),
            'global_max_burst': max(all_bursts) if all_bursts else 0,
            'burst_analysis': self._compute_percentiles(all_bursts),
            'violation_ratio': len(violations) / max(len(all_bursts), 1)
        }

    def analyze_bursts(self) -> Dict[int, BurstAnalysis]:
        """åˆ†æä¸åŒæ—¶é—´çª—å£çš„çªå‘"""
        results = {}

        for window in ANALYSIS_WINDOWS:
            all_bursts = []

            for timings in self.ip_timings.values():
                bursts = self._compute_sliding_window_bursts(timings, window)
                all_bursts.extend(bursts)

            if all_bursts:
                sorted_bursts = sorted(all_bursts)
                results[window] = BurstAnalysis(
                    window_sec=window,
                    max_burst=max(all_bursts),
                    p50=self._percentile(sorted_bursts, 50),
                    p90=self._percentile(sorted_bursts, 90),
                    p95=self._percentile(sorted_bursts, 95),
                    p99=self._percentile(sorted_bursts, 99),
                    avg=sum(all_bursts) / len(all_bursts)
                )

        return results

    def detect_anomalies(self, threshold_multiplier: float = 3.0) -> List[AnomalyAlert]:
        """å¼‚å¸¸æ£€æµ‹ï¼ˆåŸºäºç»Ÿè®¡é˜ˆå€¼ï¼‰"""
        alerts = []

        # è®¡ç®—åŸºçº¿ï¼ˆP95ï¼‰
        all_counts = []
        for timings in self.ip_timings.values():
            all_counts.append(len(timings))

        if not all_counts:
            return alerts

        sorted_counts = sorted(all_counts)
        p95_baseline = self._percentile(sorted_counts, 95)
        threshold = p95_baseline * threshold_multiplier

        # æ£€æµ‹å¼‚å¸¸ IP
        for ip, timings in self.ip_timings.items():
            count = len(timings)

            if count > threshold:
                severity = 'critical' if count > threshold * 2 else 'high'
                alerts.append(AnomalyAlert(
                    type='spike',
                    severity=severity,
                    ip=ip,
                    description=f'IP {ip} è¯·æ±‚é‡ {count} è¿œè¶…åŸºçº¿ {p95_baseline:.0f}',
                    metric_value=count,
                    threshold=threshold
                ))

        # æ£€æµ‹åˆ†å¸ƒå¼æ”»å‡»ï¼ˆå¤§é‡ä½é¢‘ IPï¼‰
        low_freq_ips = [ip for ip, t in self.ip_timings.items() if len(t) < 10]
        if len(low_freq_ips) > len(self.ip_timings) * 0.7:  # 70% éƒ½æ˜¯ä½é¢‘
            alerts.append(AnomalyAlert(
                type='distributed_attack',
                severity='medium',
                ip=None,
                description=f'æ£€æµ‹åˆ° {len(low_freq_ips)} ä¸ªä½é¢‘ IPï¼ˆå¯èƒ½æ˜¯åˆ†å¸ƒå¼æ”»å‡»ï¼‰',
                metric_value=len(low_freq_ips),
                threshold=len(self.ip_timings) * 0.7
            ))

        return alerts

    def recommend_limits(self, safety_margin: float = 0.2) -> Dict[str, Any]:
        """æ¨èé™æµå‚æ•°ï¼ˆæ”¯æŒå¤šçª—å£ï¼‰"""
        burst_analysis = self.analyze_bursts()

        # å¤šæ—¶é—´çª—å£æ¨è
        multi_window_recommendations = {}

        for window_sec in [10, 30, 60, 300, 3600, 86400]:  # 10s, 30s, 1min, 5min, 1h, 24h
            window_bursts = self._compute_window_bursts(window_sec)
            if not window_bursts:
                continue

            sorted_bursts = sorted(window_bursts)
            p99 = self._percentile(sorted_bursts, 99)
            p95 = self._percentile(sorted_bursts, 95)
            avg = sum(window_bursts) / len(window_bursts)

            # æ ¹æ®çª—å£å¤§å°è®¡ç®— rate
            if window_sec <= 60:
                # çŸ­çª—å£ï¼šåŸºäºçªå‘è®¡ç®—
                rate_per_sec = p99 / window_sec
            else:
                # é•¿çª—å£ï¼šåŸºäºå¹³å‡å€¼è®¡ç®—
                rate_per_sec = avg / window_sec

            rate_per_sec = max(1, round(rate_per_sec * (1 + safety_margin)))

            # è®¡ç®— burstï¼ˆæ ¹æ®çª—å£è°ƒæ•´ï¼‰
            if window_sec <= 10:
                burst_base = p99
            elif window_sec <= 60:
                burst_base = max(p95, p99 * 0.8)
            else:
                burst_base = p95

            burst = max(5, int(burst_base * (1 + safety_margin)))

            # ç”Ÿæˆä¸‰ç§æ¨¡å¼
            multi_window_recommendations[f'{window_sec}s'] = {
                'window_seconds': window_sec,
                'window_display': self._format_duration(window_sec),
                'statistics': {
                    'p95': p95,
                    'p99': p99,
                    'avg': round(avg, 1),
                    'max': max(window_bursts)
                },
                'strict': {
                    'rate': max(1, rate_per_sec // 2),
                    'burst': max(5, int(burst * 0.5)),
                    'description': 'ä¸¥æ ¼æ¨¡å¼ï¼šé€‚ç”¨äºé«˜å®‰å…¨éœ€æ±‚åœºæ™¯'
                },
                'balanced': {
                    'rate': rate_per_sec,
                    'burst': burst,
                    'description': 'å‡è¡¡æ¨¡å¼ï¼šæ¨èçš„ç”Ÿäº§é…ç½®'
                },
                'loose': {
                    'rate': rate_per_sec * 2,
                    'burst': int(burst * 1.5),
                    'description': 'å®½æ¾æ¨¡å¼ï¼šé€‚ç”¨äºçªå‘é«˜å³°åœºæ™¯'
                }
            }

        # ä¼ ç»Ÿçš„åŸºäºåˆ†æçª—å£çš„æ¨èï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        rate_base = burst_analysis.get(60)
        if rate_base:
            rate_rps = max(1, round(rate_base.p99 / 60 * (1 + safety_margin)))
        else:
            rate_rps = 10

        burst_1s = burst_analysis.get(1, BurstAnalysis(1, 10, 5, 8, 9, 10, 7))
        burst_5s = burst_analysis.get(5, BurstAnalysis(5, 20, 10, 15, 18, 20, 14))

        burst_base = max(burst_1s.p99, burst_5s.p99)
        burst_base = int(burst_base * (1 + safety_margin))

        return {
            'multi_window': multi_window_recommendations,
            'default': {
                'strict': {
                    'rate': max(rate_rps // 2, 1),
                    'burst': max(5, int(burst_base * 0.5)),
                    'description': 'ä¸¥æ ¼æ¨¡å¼ï¼šé€‚ç”¨äºé«˜å®‰å…¨éœ€æ±‚åœºæ™¯'
                },
                'balanced': {
                    'rate': rate_rps,
                    'burst': max(10, burst_base),
                    'description': 'å‡è¡¡æ¨¡å¼ï¼šæ¨èçš„ç”Ÿäº§é…ç½®'
                },
                'loose': {
                    'rate': rate_rps * 2,
                    'burst': max(20, int(burst_base * 2)),
                    'description': 'å®½æ¾æ¨¡å¼ï¼šé€‚ç”¨äºçªå‘é«˜å³°åœºæ™¯'
                }
            },
            'burst_analysis': {k: asdict(v) for k, v in burst_analysis.items()}
        }

    def _compute_window_bursts(self, window_sec: int) -> List[int]:
        """è®¡ç®—æŒ‡å®šçª—å£çš„æ‰€æœ‰çªå‘"""
        all_bursts = []
        window_td = timedelta(seconds=window_sec)

        for timings in self.ip_timings.values():
            if not timings:
                continue

            left = 0
            for right in range(len(timings)):
                while timings[right] - timings[left] > window_td:
                    left += 1
                all_bursts.append(right - left + 1)

        return all_bursts

    @staticmethod
    def _format_duration(seconds: int) -> str:
        """æ ¼å¼åŒ–æ—¶é•¿æ˜¾ç¤º"""
        if seconds < 60:
            return f"{seconds}ç§’"
        elif seconds < 3600:
            return f"{seconds // 60}åˆ†é’Ÿ"
        elif seconds < 86400:
            return f"{seconds // 3600}å°æ—¶"
        else:
            return f"{seconds // 86400}å¤©"

    def analyze_uri_patterns(self, top_n: int = 30) -> Dict[str, Any]:
        """åˆ†æ URI è®¿é—®æ¨¡å¼"""
        top_uris = self.uri_counter.most_common(top_n)

        uri_details = []
        for uri, count in top_uris:
            timings = self.uri_timings.get(uri, [])
            if not timings:
                continue

            # è®¡ç®— 10s æœ€å¤§çªå‘
            max_burst = self._compute_max_burst(timings, 10)

            # åˆ¤æ–­ URI ç±»å‹
            uri_type = self._classify_uri(uri)

            uri_details.append({
                'uri': uri,
                'request_count': count,
                'max_burst_10s': max_burst,
                'uri_type': uri_type,
                'recommended_burst': self._recommend_uri_burst(uri_type, max_burst)
            })

        return {
            'top_uris': uri_details,
            'total_unique_uris': len(self.uri_counter)
        }

    def simulate_policy(self, rate: int, burst: int) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿé™æµç­–ç•¥æ•ˆæœï¼ˆA/B æµ‹è¯•ï¼‰"""
        blocked_requests = 0
        blocked_ips = set()
        ip_tokens = {}  # ä»¤ç‰Œæ¡¶æ¨¡æ‹Ÿ

        for rec in sorted(self.records, key=lambda x: x.timestamp):
            ip = rec.ip

            if ip not in ip_tokens:
                ip_tokens[ip] = {
                    'tokens': burst,
                    'last_refill': rec.timestamp
                }

            bucket = ip_tokens[ip]

            # è¡¥å……ä»¤ç‰Œ
            time_delta = (rec.timestamp - bucket['last_refill']).total_seconds()
            new_tokens = time_delta * rate
            bucket['tokens'] = min(burst, bucket['tokens'] + new_tokens)
            bucket['last_refill'] = rec.timestamp

            # æ¶ˆè€—ä»¤ç‰Œ
            if bucket['tokens'] >= 1:
                bucket['tokens'] -= 1
            else:
                blocked_requests += 1
                blocked_ips.add(ip)

        return {
            'rate': rate,
            'burst': burst,
            'total_requests': len(self.records),
            'blocked_requests': blocked_requests,
            'blocked_ratio': blocked_requests / len(self.records),
            'affected_ips': len(blocked_ips),
            'pass_through_ratio': 1 - (blocked_requests / len(self.records))
        }

    # ---- è¾…åŠ©æ–¹æ³• ----

    def _compute_sliding_window_bursts(self, timings: List[datetime], window_sec: int) -> List[int]:
        """æ»‘åŠ¨çª—å£çªå‘è®¡ç®—"""
        if not timings:
            return []

        bursts = []
        left = 0
        window_td = timedelta(seconds=window_sec)

        for right in range(len(timings)):
            while timings[right] - timings[left] > window_td:
                left += 1
            bursts.append(right - left + 1)

        return bursts

    def _compute_max_burst(self, timings: List[datetime], window_sec: int) -> int:
        """è®¡ç®—æœ€å¤§çªå‘"""
        bursts = self._compute_sliding_window_bursts(timings, window_sec)
        return max(bursts) if bursts else 0

    @staticmethod
    def _percentile(sorted_data: List[int], p: float) -> int:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not sorted_data:
            return 0
        index = int(len(sorted_data) * p / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]

    @staticmethod
    def _compute_percentiles(data: List[int]) -> Dict[str, int]:
        """è®¡ç®—å¤šä¸ªç™¾åˆ†ä½æ•°"""
        if not data:
            return {'p50': 0, 'p90': 0, 'p95': 0, 'p99': 0}

        sorted_data = sorted(data)
        return {
            'p50': RateLimitAnalyzer._percentile(sorted_data, 50),
            'p90': RateLimitAnalyzer._percentile(sorted_data, 90),
            'p95': RateLimitAnalyzer._percentile(sorted_data, 95),
            'p99': RateLimitAnalyzer._percentile(sorted_data, 99),
        }

    @staticmethod
    def _classify_uri(uri: str) -> str:
        """åˆ†ç±» URIï¼ˆç”¨äºå·®å¼‚åŒ–é™æµï¼‰"""
        uri_lower = uri.lower()

        if any(kw in uri_lower for kw in ['login', 'auth', 'signin', 'authenticate']):
            return 'auth'
        elif any(kw in uri_lower for kw in ['pay', 'checkout', 'order', 'purchase']):
            return 'payment'
        elif any(kw in uri_lower for kw in ['api', 'v1', 'v2', 'graphql']):
            return 'api'
        elif any(kw in uri_lower for kw in ['admin', 'manage', 'dashboard']):
            return 'admin'
        elif any(kw in uri_lower for kw in ['static', 'assets', 'cdn', '.js', '.css', '.jpg', '.png']):
            return 'static'
        else:
            return 'general'

    @staticmethod
    def _recommend_uri_burst(uri_type: str, max_burst: int) -> int:
        """æ ¹æ® URI ç±»å‹æ¨è burst"""
        # åŸºç¡€ burstï¼ˆåŠ  20% å®‰å…¨è¾¹é™…ï¼‰
        base = int(max_burst * 1.2)

        # æŒ‰ç±»å‹è°ƒæ•´
        adjustments = {
            'auth': 0.5,  # è®¤è¯ç±»ä¸¥æ ¼
            'payment': 0.6,  # æ”¯ä»˜ç±»ä¸¥æ ¼
            'api': 1.0,  # API æ­£å¸¸
            'admin': 0.7,  # ç®¡ç†ç±»è¾ƒä¸¥
            'static': 2.0,  # é™æ€èµ„æºå®½æ¾
            'general': 1.0  # æ™®é€šé¡µé¢
        }

        multiplier = adjustments.get(uri_type, 1.0)
        return max(3, int(base * multiplier))


# ========================
# æŠ¥å‘Šç”Ÿæˆ
# ========================
class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    @staticmethod
    def print_summary(analyzer: RateLimitAnalyzer, eval_result: Dict[str, Any]):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "=" * 70)
        print("ğŸ“Š é™æµç­–ç•¥åˆ†ææŠ¥å‘Š")
        print("=" * 70)

        print(f"\nã€æ•°æ®æ¦‚è§ˆã€‘")
        print(f"  æ€»è¯·æ±‚æ•°: {eval_result['total_requests']:,}")
        print(f"  ç‹¬ç«‹ IP æ•°: {eval_result['total_unique_ips']:,}")
        print(f"  åˆ†æçª—å£: {eval_result['window_seconds']}ç§’")
        print(f"  å½“å‰é™åˆ¶: {eval_result['current_limit']} æ¬¡/çª—å£")

        print(f"\nã€å½“å‰ç­–ç•¥è¯„ä¼°ã€‘")
        print(f"  è¿è§„æ¬¡æ•°: {eval_result['violations_count']:,}")
        print(f"  è¿è§„ IP æ•°: {eval_result['violation_ips_count']}")
        print(f"  è¿è§„æ¯”ä¾‹: {eval_result['violation_ratio']:.2%}")
        print(f"  å…¨å±€æœ€å¤§çªå‘: {eval_result['global_max_burst']}")

        burst = eval_result['burst_analysis']
        print(f"\nã€çªå‘åˆ†å¸ƒã€‘")
        print(f"  P50: {burst['p50']}  P90: {burst['p90']}  P95: {burst['p95']}  P99: {burst['p99']}")

        # ç­–ç•¥å»ºè®®
        if eval_result['violation_ratio'] < 0.01:
            print(f"\nâœ… ç­–ç•¥åˆç†ï¼ˆè¿è§„ <1%ï¼‰")
        elif eval_result['violation_ratio'] < 0.05:
            print(f"\nâš ï¸  å»ºè®®é€‚å½“æ”¾å®½ï¼ˆè¿è§„ <5%ï¼‰")
        else:
            print(f"\nâŒ ç­–ç•¥è¿‡ä¸¥ï¼ˆè¿è§„ â‰¥5%ï¼‰ï¼Œå»ºè®®è°ƒæ•´ï¼")

    @staticmethod
    def print_recommendations(recommendations: Dict[str, Any]):
        """æ‰“å°æ¨èé…ç½®ï¼ˆæ”¯æŒå¤šçª—å£ï¼‰"""
        print("\n" + "=" * 90)
        print("ğŸ¯ å¤šæ—¶é—´çª—å£é™æµç­–ç•¥æ¨è")
        print("=" * 90)

        if 'multi_window' in recommendations:
            # æ–°ç‰ˆå¤šçª—å£æ¨è
            multi_window = recommendations['multi_window']

            # æ‰“å°å¯¹æ¯”è¡¨
            print("\nã€æ—¶é—´çª—å£å¯¹æ¯”è¡¨ã€‘")
            print(f"{'çª—å£':<10} {'P95':<8} {'P99':<8} {'å¹³å‡':<8} {'æœ€å¤§':<8} | {'æ¨èrate':<12} {'æ¨èburst':<12}")
            print("-" * 90)

            for window_key in sorted(multi_window.keys(), key=lambda x: int(x.rstrip('s'))):
                window_data = multi_window[window_key]
                stats = window_data['statistics']
                balanced = window_data['balanced']

                print(f"{window_data['window_display']:<10} "
                      f"{stats['p95']:<8} "
                      f"{stats['p99']:<8} "
                      f"{stats['avg']:<8.1f} "
                      f"{stats['max']:<8} | "
                      f"{balanced['rate']}r/s{'':<7} "
                      f"{balanced['burst']}")

            # è¯¦ç»†æ¨èï¼ˆé€‰æ‹©å‡ ä¸ªå…³é”®çª—å£ï¼‰
            key_windows = ['10s', '60s', '3600s']
            for window_key in key_windows:
                if window_key not in multi_window:
                    continue

                window_data = multi_window[window_key]
                print(f"\n{'=' * 90}")
                print(f"ã€{window_data['window_display']} çª—å£é™æµé…ç½®ã€‘")
                print(f"{'=' * 90}")

                print(f"\nç»Ÿè®¡æ•°æ®: P95={window_data['statistics']['p95']}, "
                      f"P99={window_data['statistics']['p99']}, "
                      f"å¹³å‡={window_data['statistics']['avg']:.1f}, "
                      f"æœ€å¤§={window_data['statistics']['max']}")

                for mode in ['strict', 'balanced', 'loose']:
                    config = window_data[mode]
                    print(f"\nã€{mode.upper()} æ¨¡å¼ã€‘{config['description']}")
                    print(f"  rate={config['rate']}r/s  burst={config['burst']}")

                    # Nginx é…ç½®ç¤ºä¾‹
                    zone_name = f"{mode}_{window_data['window_seconds']}s"
                    print(f"\n  # http å—é…ç½®")
                    print(f"  limit_req_zone $binary_remote_addr zone={zone_name}:10m rate={config['rate']}r/s;")
                    print(f"\n  # server/location å—é…ç½®")
                    print(f"  limit_req zone={zone_name} burst={config['burst']} nodelay;")

        # ä¼ ç»Ÿæ¨èï¼ˆé»˜è®¤æ¨¡å¼ï¼‰
        if 'default' in recommendations:
            print(f"\n{'=' * 90}")
            print("ã€é»˜è®¤æ¨èé…ç½®ï¼ˆ10ç§’çª—å£ï¼‰ã€‘")
            print(f"{'=' * 90}")

            for mode in ['strict', 'balanced', 'loose']:
                config = recommendations['default'][mode]
                print(f"\nã€{mode.upper()} æ¨¡å¼ã€‘{config['description']}")
                print(f"  rate={config['rate']}r/s  burst={config['burst']}")

        # ä½¿ç”¨å»ºè®®
        print(f"\n{'=' * 90}")
        print("ğŸ’¡ ä½¿ç”¨å»ºè®®")
        print(f"{'=' * 90}")
        print("""
1. çŸ­çª—å£ï¼ˆ10s-60sï¼‰é€‚åˆï¼š
   - é˜²æ­¢ç¬æ—¶çªå‘æ”»å‡»
   - API æ¥å£ä¿æŠ¤
   - ç™»å½•/è®¤è¯ç«¯ç‚¹

2. ä¸­çª—å£ï¼ˆ5min-1hï¼‰é€‚åˆï¼š
   - ä¸šåŠ¡é€»è¾‘é™æµ
   - é˜²æ­¢è´¦å·æ»¥ç”¨
   - çˆ¬è™«æ§åˆ¶

3. é•¿çª—å£ï¼ˆ24hï¼‰é€‚åˆï¼š
   - æ¯æ—¥é…é¢é™åˆ¶
   - é˜²æ­¢æŒç»­æ€§æ»¥ç”¨
   - ä»˜è´¹ API é™é¢

4. ç»„åˆä½¿ç”¨ï¼ˆå¤šå±‚é˜²æŠ¤ï¼‰ï¼š
   limit_req zone=short_window burst=20 nodelay;  # 10ç§’çª—å£
   limit_req zone=long_window burst=1000;         # 1å°æ—¶çª—å£
""")

    @staticmethod
    def print_uri_analysis(uri_analysis: Dict[str, Any]):
        """æ‰“å° URI åˆ†æ"""
        print("\n" + "=" * 70)
        print("ğŸŒ URI è®¿é—®æ¨¡å¼åˆ†æ")
        print("=" * 70)

        print(f"\n  æ€» URI æ•°é‡: {uri_analysis['total_unique_uris']:,}")
        print(f"\n  {'URI':<45} {'è¯·æ±‚é‡':<12} {'10sçªå‘':<10} {'ç±»å‹':<10} {'æ¨èburst'}")
        print("  " + "-" * 95)

        for uri_info in uri_analysis['top_uris'][:15]:
            uri = uri_info['uri'][:44]
            count = uri_info['request_count']
            burst = uri_info['max_burst_10s']
            uri_type = uri_info['uri_type']
            rec_burst = uri_info['recommended_burst']

            print(f"  {uri:<45} {count:<12,} {burst:<10} {uri_type:<10} {rec_burst}")

    @staticmethod
    def print_anomalies(alerts: List[AnomalyAlert]):
        """æ‰“å°å¼‚å¸¸å‘Šè­¦"""
        if not alerts:
            print("\nâœ… æœªæ£€æµ‹åˆ°å¼‚å¸¸æµé‡")
            return

        print("\n" + "=" * 70)
        print("âš ï¸  å¼‚å¸¸æµé‡å‘Šè­¦")
        print("=" * 70)

        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        by_severity = defaultdict(list)
        for alert in alerts:
            by_severity[alert.severity].append(alert)

        severity_order = ['critical', 'high', 'medium', 'low']
        severity_icons = {
            'critical': 'ğŸ”´',
            'high': 'ğŸŸ ',
            'medium': 'ğŸŸ¡',
            'low': 'ğŸŸ¢'
        }

        for severity in severity_order:
            if severity not in by_severity:
                continue

            print(f"\n{severity_icons[severity]} {severity.upper()} çº§åˆ«å‘Šè­¦:")
            for alert in by_severity[severity]:
                print(f"  - {alert.description}")
                if alert.ip:
                    print(f"    IP: {alert.ip}")
                print(f"    æŒ‡æ ‡å€¼: {alert.metric_value:.0f} (é˜ˆå€¼: {alert.threshold:.0f})")

    @staticmethod
    def print_simulation(sim_result: Dict[str, Any]):
        """æ‰“å°ç­–ç•¥æ¨¡æ‹Ÿç»“æœ"""
        print("\n" + "=" * 70)
        print("ğŸ§ª ç­–ç•¥æ•ˆæœæ¨¡æ‹Ÿï¼ˆä»¤ç‰Œæ¡¶ç®—æ³•ï¼‰")
        print("=" * 70)

        print(f"\n  é…ç½®: rate={sim_result['rate']}r/s, burst={sim_result['burst']}")
        print(f"  æ€»è¯·æ±‚: {sim_result['total_requests']:,}")
        print(f"  è¢«æ‹¦æˆª: {sim_result['blocked_requests']:,} ({sim_result['blocked_ratio']:.2%})")
        print(f"  æ”¾è¡Œç‡: {sim_result['pass_through_ratio']:.2%}")
        print(f"  å—å½±å“ IP: {sim_result['affected_ips']}")

        if sim_result['blocked_ratio'] < 0.01:
            print("\n  âœ… ç­–ç•¥å®½æ¾ï¼Œå‡ ä¹æ— è¯¯æ€")
        elif sim_result['blocked_ratio'] < 0.05:
            print("\n  âš–ï¸  ç­–ç•¥å‡è¡¡ï¼Œè¯¯æ€ç‡å¯æ¥å—")
        else:
            print("\n  âš ï¸  ç­–ç•¥ä¸¥æ ¼ï¼Œå¯èƒ½å½±å“æ­£å¸¸ç”¨æˆ·")

    @staticmethod
    def generate_nginx_config(recommendations: Dict[str, Any], uri_analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆå®Œæ•´çš„ Nginx é…ç½®ï¼ˆæ”¯æŒå¤šçª—å£ï¼‰"""
        config = []

        config.append("# ============================================")
        config.append("# Nginx å¤šå±‚é™æµé…ç½®ï¼ˆåŸºäºæ—¥å¿—åˆ†æç”Ÿæˆï¼‰")
        config.append("# ============================================\n")

        # å¤šçª—å£é™æµåŒºå®šä¹‰
        if 'multi_window' in recommendations:
            config.append("# 1. å¤šæ—¶é—´çª—å£é™æµåŒºå®šä¹‰ï¼ˆhttp å—ï¼‰")
            multi_window = recommendations['multi_window']

            # ä¸ºæ¯ä¸ªçª—å£çš„ balanced æ¨¡å¼ç”Ÿæˆé…ç½®
            for window_key in sorted(multi_window.keys(), key=lambda x: int(x.rstrip('s'))):
                window_data = multi_window[window_key]
                balanced = window_data['balanced']
                zone_name = f"limit_{window_data['window_seconds']}s"

                config.append(f"\n# {window_data['window_display']} çª—å£ (P99={window_data['statistics']['p99']})")
                config.append(f"limit_req_zone $binary_remote_addr zone={zone_name}:10m rate={balanced['rate']}r/s;")

        # URI çº§åˆ«é™æµåŒº
        config.append("\n# 2. URI çº§åˆ«é™æµåŒºï¼ˆæŒ‰ç±»å‹åˆ†ç±»ï¼‰")
        uri_types = defaultdict(list)
        for uri_info in uri_analysis['top_uris'][:10]:
            uri_types[uri_info['uri_type']].append(uri_info)

        for uri_type in ['auth', 'payment', 'api']:
            if uri_type in uri_types:
                config.append(f"limit_req_zone $binary_remote_addr zone={uri_type}_zone:5m rate=5r/s;")

        # server å—é…ç½® - å¤šå±‚é˜²æŠ¤
        config.append("\n# 3. å¤šå±‚é™æµé…ç½®ç¤ºä¾‹ï¼ˆserver å—ï¼‰")
        config.append("server {")
        config.append("    # ... å…¶ä»–é…ç½® ...")
        config.append("")

        # æ–¹æ¡ˆA: å•ä¸€çª—å£ï¼ˆç®€å•ï¼‰
        config.append("    # ========== æ–¹æ¡ˆ A: å•ä¸€çª—å£ï¼ˆæ¨èæ–°æ‰‹ä½¿ç”¨ï¼‰ ==========")
        if 'multi_window' in recommendations and '10s' in recommendations['multi_window']:
            balanced_10s = recommendations['multi_window']['10s']['balanced']
            config.append(f"    # 10ç§’çª—å£å…¨å±€é™æµ")
            config.append(f"    limit_req zone=limit_10s burst={balanced_10s['burst']} nodelay;")

        # æ–¹æ¡ˆB: åŒå±‚é˜²æŠ¤ï¼ˆæ¨èï¼‰
        config.append("\n    # ========== æ–¹æ¡ˆ B: åŒå±‚é˜²æŠ¤ï¼ˆæ¨èç”Ÿäº§ä½¿ç”¨ï¼‰ ==========")
        config.append("    # çŸ­çª—å£ï¼šé˜²æ­¢ç¬æ—¶çªå‘")
        if 'multi_window' in recommendations and '10s' in recommendations['multi_window']:
            burst_10s = recommendations['multi_window']['10s']['balanced']['burst']
            config.append(f"    limit_req zone=limit_10s burst={burst_10s} nodelay;")

        config.append("\n    # é•¿çª—å£ï¼šé˜²æ­¢æŒç»­æ»¥ç”¨")
        if 'multi_window' in recommendations and '3600s' in recommendations['multi_window']:
            burst_1h = recommendations['multi_window']['3600s']['balanced']['burst']
            config.append(f"    limit_req zone=limit_3600s burst={burst_1h};")

        # æ–¹æ¡ˆC: å¤šå±‚é˜²æŠ¤ï¼ˆé«˜çº§ï¼‰
        config.append("\n    # ========== æ–¹æ¡ˆ C: ä¸‰å±‚é˜²æŠ¤ï¼ˆé«˜å®‰å…¨åœºæ™¯ï¼‰ ==========")
        windows = ['10s', '60s', '3600s']
        for window_key in windows:
            if 'multi_window' in recommendations and window_key in recommendations['multi_window']:
                window_data = recommendations['multi_window'][window_key]
                burst = window_data['balanced']['burst']
                nodelay = ' nodelay' if window_key == '10s' else ''
                config.append(f"    # limit_req zone=limit_{window_data['window_seconds']}s burst={burst}{nodelay};")

        # URI ç‰¹å®šé…ç½®
        config.append("\n    # ========== URI çº§åˆ«ç²¾ç»†åŒ–é™æµ ==========")

        config.append("\n    # è®¤è¯æ¥å£ï¼ˆæœ€ä¸¥æ ¼ï¼‰")
        for uri_info in uri_types.get('auth', [])[:3]:
            config.append(f"    location = {uri_info['uri']} {{")
            config.append(f"        limit_req zone=auth_zone burst={uri_info['recommended_burst']} nodelay;")
            if 'multi_window' in recommendations and '60s' in recommendations['multi_window']:
                config.append(f"        limit_req zone=limit_60s burst=20;  # é¢å¤–çš„1åˆ†é’Ÿé™åˆ¶")
            config.append("        # ... å…¶ä»–é…ç½® ...")
            config.append("    }")

        config.append("\n    # æ”¯ä»˜æ¥å£ï¼ˆä¸¥æ ¼ï¼‰")
        for uri_info in uri_types.get('payment', [])[:3]:
            config.append(f"    location ~ {uri_info['uri']} {{")
            config.append(f"        limit_req zone=payment_zone burst={uri_info['recommended_burst']} nodelay;")
            config.append("        # ... å…¶ä»–é…ç½® ...")
            config.append("    }")

        config.append("\n    # API æ¥å£ï¼ˆé€‚ä¸­ï¼‰")
        for uri_info in uri_types.get('api', [])[:3]:
            config.append(f"    location ~ ^{uri_info['uri']} {{")
            config.append(f"        limit_req zone=api_zone burst={uri_info['recommended_burst']} nodelay;")
            config.append("        # ... å…¶ä»–é…ç½® ...")
            config.append("    }")

        config.append("}")

        # ç›‘æ§å’Œæ—¥å¿—é…ç½®
        config.append("\n# 4. ç›‘æ§å’Œæ—¥å¿—é…ç½®")
        config.append("limit_req_log_level warn;  # è®°å½•è¢«é™æµçš„è¯·æ±‚")
        config.append("limit_req_status 429;      # è¿”å› 429 çŠ¶æ€ç ")

        # ä½¿ç”¨è¯´æ˜
        config.append("\n# ============================================")
        config.append("# ä½¿ç”¨è¯´æ˜")
        config.append("# ============================================")
        config.append("""
# 1. é€‰æ‹©åˆé€‚çš„æ–¹æ¡ˆï¼š
#    - æ–¹æ¡ˆA: é€‚åˆæµé‡ç®€å•çš„å°å‹åº”ç”¨
#    - æ–¹æ¡ˆB: æ¨èå¤§å¤šæ•°ç”Ÿäº§ç¯å¢ƒä½¿ç”¨
#    - æ–¹æ¡ˆC: é€‚åˆé«˜å®‰å…¨éœ€æ±‚åœºæ™¯

# 2. çª—å£é€‰æ‹©å»ºè®®ï¼š
#    - 10s:  é˜²æ­¢ç¬æ—¶çªå‘ã€DDoS æ”»å‡»
#    - 60s:  API æ¥å£å¸¸è§„ä¿æŠ¤
#    - 1h:   é˜²æ­¢è´¦å·æ»¥ç”¨ã€çˆ¬è™«
#    - 24h:  æ¯æ—¥é…é¢ã€ä»˜è´¹é™åˆ¶

# 3. burst å‚æ•°è¯´æ˜ï¼š
#    - nodelay: ç«‹å³å¤„ç†çªå‘ï¼Œè¶…è¿‡åˆ™æ‹’ç»ï¼ˆé€‚åˆçŸ­çª—å£ï¼‰
#    - æ—  nodelay: æ’é˜Ÿç­‰å¾…ï¼ˆé€‚åˆé•¿çª—å£ï¼Œé¿å…ç¬æ—¶æ‹’ç»ï¼‰

# 4. ç°åº¦ä¸Šçº¿æ­¥éª¤ï¼š
#    a) å…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯é…ç½®
#    b) ç”Ÿäº§ç¯å¢ƒä» loose æ¨¡å¼å¼€å§‹
#    c) ç›‘æ§ 429 é”™è¯¯ç‡ï¼Œé€æ­¥è°ƒæ•´
#    d) æœ€ç»ˆç¨³å®šåœ¨ balanced æ¨¡å¼

# 5. ç›‘æ§æŒ‡æ ‡ï¼š
#    - 429 é”™è¯¯ç‡ < 0.5%: é…ç½®åˆç†
#    - 429 é”™è¯¯ç‡ 0.5-2%: å¯ä»¥æ¥å—
#    - 429 é”™è¯¯ç‡ > 2%: éœ€è¦æ”¾å®½é™åˆ¶
""")

        return "\n".join(config)

    @staticmethod
    def save_json_report(
            eval_result: Dict[str, Any],
            recommendations: Dict[str, Any],
            uri_analysis: Dict[str, Any],
            anomalies: List[AnomalyAlert],
            sim_result: Optional[Dict[str, Any]],
            output_file: str
    ):
        """ä¿å­˜ JSON æŠ¥å‘Š"""
        report = {
            'generated_at': datetime.now().isoformat(),
            'evaluation': eval_result,
            'recommendations': recommendations,
            'uri_analysis': uri_analysis,
            'anomalies': [asdict(a) for a in anomalies],
            'simulation': sim_result
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)

        print(f"\nğŸ’¾ JSON æŠ¥å‘Šå·²ä¿å­˜: {os.path.abspath(output_file)}")


# ========================
# å‘½ä»¤è¡Œå…¥å£
# ========================
def parse_time_range(last_arg: str) -> Tuple[datetime, datetime]:
    """è§£ææ—¶é—´èŒƒå›´å‚æ•°"""
    now = datetime.now().astimezone()

    match = re.match(r'(\d+)([hdw])', last_arg.lower())
    if not match:
        raise ValueError("æ—¶é—´æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º: 1h, 24h, 7d, 1w")

    value, unit = int(match.group(1)), match.group(2)

    if unit == 'h':
        delta = timedelta(hours=value)
    elif unit == 'd':
        delta = timedelta(days=value)
    elif unit == 'w':
        delta = timedelta(weeks=value)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ—¶é—´å•ä½: {unit}")

    return (now - delta, now)


def main():
    parser = argparse.ArgumentParser(
        description="ç”Ÿäº§ç¯å¢ƒé™æµç­–ç•¥åˆ†æå·¥å…· v2.0",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºç¡€åˆ†æ
  %(prog)s access.log

  # åˆ†ææœ€è¿‘ 24 å°æ—¶
  %(prog)s access.log --last 24h

  # è‡ªå®šä¹‰é™æµå‚æ•°è¯„ä¼°
  %(prog)s access.log --window 10 --limit 40

  # å®Œæ•´æŠ¥å‘Šï¼ˆå« JSON è¾“å‡ºï¼‰
  %(prog)s access.log --last 24h --output-json report.json --output-config nginx.conf

  # æ’é™¤å†…éƒ¨ IP
  %(prog)s access.log --exclude-ip "10.0.0.0/8,192.168.0.0/16"
        """
    )

    # å¿…éœ€å‚æ•°
    parser.add_argument("logfiles", nargs='+', help="æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .gz å‹ç¼©ï¼‰")

    # åˆ†æå‚æ•°
    parser.add_argument("--window", type=int, default=DEFAULT_WINDOW_SEC,
                        help=f"æ—¶é—´çª—å£ï¼ˆç§’ï¼Œé»˜è®¤ {DEFAULT_WINDOW_SEC}ï¼‰")
    parser.add_argument("--limit", type=int, default=DEFAULT_MAX_REQ,
                        help=f"å½“å‰é™æµé˜ˆå€¼ï¼ˆé»˜è®¤ {DEFAULT_MAX_REQ}ï¼‰")
    parser.add_argument("--last", type=str, help="åˆ†ææ—¶é—´èŒƒå›´ï¼Œå¦‚: 1h, 24h, 7d")
    parser.add_argument("--margin", type=float, default=0.2,
                        help="å®‰å…¨è¾¹é™…ç³»æ•°ï¼ˆé»˜è®¤ 0.2 = 20%%ï¼‰")

    # è¿‡æ»¤å™¨
    parser.add_argument("--exclude-ip", type=str, default="",
                        help="æ’é™¤çš„ IP/CIDRï¼Œé€—å·åˆ†éš”")
    parser.add_argument("--exclude-file", type=str,
                        help="æ’é™¤ IP åˆ—è¡¨æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰")
    parser.add_argument("--include-status", type=str, default="2**,3**",
                        help="åŒ…å«çš„çŠ¶æ€ç æ¨¡å¼ï¼ˆé»˜è®¤ 2**,3** = åªç»Ÿè®¡æˆåŠŸè¯·æ±‚ï¼Œè‡ªåŠ¨æ’é™¤ 4xx/5xxï¼‰")
    parser.add_argument("--exclude-status", type=str,
                        help="é¢å¤–æ’é™¤çš„çŠ¶æ€ç ï¼ˆå¦‚ 301,302ï¼‰")
    parser.add_argument("--include-errors", action="store_true",
                        help="åŒ…å« 4xx/5xx é”™è¯¯ç ï¼ˆé»˜è®¤è‡ªåŠ¨æ’é™¤ï¼‰")
    parser.add_argument("--exclude-ua", type=str,
                        help="é¢å¤–æ’é™¤çš„ UA å…³é”®è¯ï¼Œé€—å·åˆ†éš”")
    parser.add_argument("--no-exclude-ua", action="store_true",
                        help="ç¦ç”¨ UA è¿‡æ»¤")

    # æ—¥å¿—æ ¼å¼
    parser.add_argument("--log-format", type=str, default=DEFAULT_LOG_FORMAT,
                        help="è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼")

    # é«˜çº§åŠŸèƒ½
    parser.add_argument("--detect-anomalies", action="store_true",
                        help="å¯ç”¨å¼‚å¸¸æ£€æµ‹")
    parser.add_argument("--anomaly-threshold", type=float, default=3.0,
                        help="å¼‚å¸¸æ£€æµ‹é˜ˆå€¼å€æ•°ï¼ˆé»˜è®¤ 3.0ï¼‰")
    parser.add_argument("--simulate", action="store_true",
                        help="æ¨¡æ‹Ÿæ¨èç­–ç•¥çš„æ•ˆæœ")

    # è¾“å‡º
    parser.add_argument("--output-json", type=str,
                        help="JSON æŠ¥å‘Šè¾“å‡ºè·¯å¾„")
    parser.add_argument("--output-config", type=str,
                        help="Nginx é…ç½®æ–‡ä»¶è¾“å‡ºè·¯å¾„")
    parser.add_argument("--quiet", action="store_true",
                        help="é™é»˜æ¨¡å¼ï¼ˆä»…è¾“å‡ºæ–‡ä»¶ï¼‰")
    parser.add_argument("--debug", action="store_true",
                        help="è°ƒè¯•æ¨¡å¼ï¼ˆæ˜¾ç¤ºè¯¦ç»†çš„è§£æä¿¡æ¯ï¼‰")
    parser.add_argument("--test-parse", type=int,
                        help="æµ‹è¯•æ¨¡å¼ï¼šåªè§£æå‰ N è¡Œå¹¶æ˜¾ç¤ºç»“æœ")

    args = parser.parse_args()

    # ---- æµ‹è¯•æ¨¡å¼ ----
    if args.test_parse:
        print(f"[TEST] æµ‹è¯•æ¨¡å¼ï¼šè§£æå‰ {args.test_parse} è¡Œ", file=sys.stderr)
        print(f"[TEST] ä½¿ç”¨æ—¥å¿—æ ¼å¼: {args.log_format}\n", file=sys.stderr)

        log_parser = OptimizedLogParser(args.log_format)

        test_count = 0
        success_count = 0

        for logfile in args.logfiles:
            if not os.path.exists(logfile):
                print(f"[ERROR] æ–‡ä»¶ä¸å­˜åœ¨: {logfile}", file=sys.stderr)
                continue

            print(f"[TEST] è¯»å–æ–‡ä»¶: {logfile}\n", file=sys.stderr)

            with open_log_file(logfile) as f:
                for line in f:
                    test_count += 1
                    if test_count > args.test_parse:
                        break

                    print(f"{'=' * 70}")
                    print(f"[TEST] ç¬¬ {test_count} è¡Œ:")
                    print(f"  åŸå§‹æ—¥å¿—: {line.strip()}")

                    parsed = log_parser.parse(line)
                    if parsed:
                        success_count += 1
                        print(f"  âœ“ è§£ææˆåŠŸ:")
                        for key, value in parsed.items():
                            if value:
                                display_value = value[:80] + '...' if len(value) > 80 else value
                                print(f"    {key:12} = {display_value}")
                    else:
                        print(f"  âœ— è§£æå¤±è´¥")
                    print()

        print(f"{'=' * 70}")
        print(f"[TEST] æµ‹è¯•å®Œæˆ: {success_count}/{test_count} è¡ŒæˆåŠŸè§£æ ({success_count / test_count * 100:.1f}%)")

        if success_count == 0:
            print(f"\n[å»ºè®®] æ—¥å¿—æ ¼å¼å¯èƒ½ä¸åŒ¹é…ã€‚ä½ çš„æ—¥å¿—æ ·ä¾‹:")
            print(
                f"  139.224.207.164 - - [11/Dec/2025:00:00:06 +0800] \"GET /api/global HTTP/1.1\" 200 693 \"-\" \"node\"")
            print(f"\n[å»ºè®®] è¿™æ˜¯æ ‡å‡†çš„ Nginx combined æ ¼å¼ï¼Œåº”è¯¥å¯ä»¥è‡ªåŠ¨è§£æã€‚")
            print(f"[å»ºè®®] å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥:")
            print(f"  1. æ–‡ä»¶ç¼–ç æ˜¯å¦ä¸º UTF-8")
            print(f"  2. æ˜¯å¦æœ‰ç‰¹æ®Šå­—ç¬¦æˆ–æ ¼å¼å¼‚å¸¸")
            print(f"  3. å°è¯•ä½¿ç”¨ --debug å‚æ•°è·å–æ›´å¤šä¿¡æ¯")

        sys.exit(0)

    # ---- åˆå§‹åŒ–è¿‡æ»¤å™¨ ----
    print("[INFO] åˆå§‹åŒ–è¿‡æ»¤å™¨...", file=sys.stderr)

    ip_filter = IPFilter(
        args.exclude_ip.split(',') if args.exclude_ip else [],
        args.exclude_file
    )

    # å¦‚æœç”¨æˆ·è¦åŒ…å«é”™è¯¯ç ï¼Œéœ€è¦ä¿®æ”¹ include_status
    include_status = args.include_status
    if args.include_errors:
        # æ·»åŠ  4xx å’Œ 5xx
        include_status = f"{include_status},4**,5**"
        print(f"[INFO] å·²å¯ç”¨é”™è¯¯ç ç»Ÿè®¡ï¼ˆåŒ…å« 4xx/5xxï¼‰", file=sys.stderr)

    status_filter = StatusFilter(include_status, args.exclude_status)

    # æ‰“å°çŠ¶æ€ç è¿‡æ»¤ä¿¡æ¯
    filter_info = status_filter.get_filter_info()
    print(f"[INFO] çŠ¶æ€ç è¿‡æ»¤é…ç½®:", file=sys.stderr)
    print(f"[INFO]   - åŒ…å«çŠ¶æ€ç æ•°é‡: {filter_info['include_codes_count']}", file=sys.stderr)
    print(f"[INFO]   - æ’é™¤çŠ¶æ€ç æ•°é‡: {filter_info['exclude_codes_count']}", file=sys.stderr)
    print(f"[INFO]   - è‡ªåŠ¨æ’é™¤ 4xx/5xx: {'æ˜¯' if filter_info['auto_exclude_errors'] else 'å¦'}", file=sys.stderr)
    if filter_info['example_included']:
        print(f"[INFO]   - ç¤ºä¾‹åŒ…å«: {filter_info['example_included']}", file=sys.stderr)

    exclude_ua_keywords = [] if args.no_exclude_ua else DEFAULT_EXCLUDE_UA_KEYWORDS.copy()
    if args.exclude_ua:
        exclude_ua_keywords.extend([kw.strip().lower() for kw in args.exclude_ua.split(',')])
    ua_filter = UAFilter(exclude_ua_keywords)

    print(f"[INFO] User-Agent è¿‡æ»¤: {len(exclude_ua_keywords)} ä¸ªå…³é”®è¯", file=sys.stderr)

    log_parser = OptimizedLogParser(args.log_format)

    # ---- è§£ææ—¶é—´èŒƒå›´ ----
    time_range = None
    if args.last:
        try:
            time_range = parse_time_range(args.last)
            print(f"[INFO] åˆ†ææ—¶é—´èŒƒå›´: {time_range[0]} è‡³ {time_range[1]}", file=sys.stderr)
        except ValueError as e:
            print(f"[ERROR] {e}", file=sys.stderr)
            sys.exit(1)

    # ---- æå–è®°å½•ï¼ˆæµå¼å¤„ç†ï¼‰----
    print("[INFO] å¼€å§‹æå–æ—¥å¿—è®°å½•...", file=sys.stderr)
    records = list(stream_records(
        args.logfiles,
        ip_filter,
        status_filter,
        ua_filter,
        log_parser,
        time_range
    ))

    if not records:
        print("[ERROR] æœªæ‰¾åˆ°æœ‰æ•ˆè®°å½•ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å’Œè¿‡æ»¤æ¡ä»¶", file=sys.stderr)
        sys.exit(1)

    # ---- åˆ†æ ----
    print("[INFO] å¼€å§‹åˆ†æ...", file=sys.stderr)
    analyzer = RateLimitAnalyzer(records)

    eval_result = analyzer.evaluate_policy(args.window, args.limit)
    recommendations = analyzer.recommend_limits(args.margin)
    uri_analysis = analyzer.analyze_uri_patterns()

    # å¼‚å¸¸æ£€æµ‹
    anomalies = []
    if args.detect_anomalies:
        print("[INFO] æ‰§è¡Œå¼‚å¸¸æ£€æµ‹...", file=sys.stderr)
        anomalies = analyzer.detect_anomalies(args.anomaly_threshold)

    # ç­–ç•¥æ¨¡æ‹Ÿ
    sim_result = None
    if args.simulate and 'balanced' in recommendations:
        print("[INFO] æ¨¡æ‹Ÿæ¨èç­–ç•¥æ•ˆæœ...", file=sys.stderr)
        balanced = recommendations['balanced']
        sim_result = analyzer.simulate_policy(balanced['rate'], balanced['burst'])

    # ---- è¾“å‡ºæŠ¥å‘Š ----
    if not args.quiet:
        reporter = ReportGenerator()
        reporter.print_summary(analyzer, eval_result)
        reporter.print_recommendations(recommendations)
        reporter.print_uri_analysis(uri_analysis)

        if anomalies:
            reporter.print_anomalies(anomalies)

        if sim_result:
            reporter.print_simulation(sim_result)

    # ---- ä¿å­˜æ–‡ä»¶ ----
    if args.output_json:
        ReportGenerator.save_json_report(
            eval_result,
            recommendations,
            uri_analysis,
            anomalies,
            sim_result,
            args.output_json
        )

    if args.output_config:
        config_content = ReportGenerator.generate_nginx_config(recommendations, uri_analysis)
        with open(args.output_config, 'w', encoding='utf-8') as f:
            f.write(config_content)
        print(f"ğŸ“ Nginx é…ç½®å·²ä¿å­˜: {os.path.abspath(args.output_config)}", file=sys.stderr)

    print("\nâœ¨ åˆ†æå®Œæˆï¼", file=sys.stderr)


if __name__ == '__main__':
    main()